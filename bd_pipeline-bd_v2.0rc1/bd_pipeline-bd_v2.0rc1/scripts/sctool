#!/usr/bin/env Rscript
# the command line api of data analysis of biological experiments
if (!requireNamespace('argparse', quietly = TRUE)) {
  stop("Please install argparse to parse the command line paramters!")
}
suppressPackageStartupMessages( library("argparse") )
suppressPackageStartupMessages( library("magrittr") )
suppressPackageStartupMessages( library("future") )
suppressPackageStartupMessages( library("future.apply") )
suppressPackageStartupMessages( library("docopt") )
suppressPackageStartupMessages( library("dplyr") )
library(Matrix)
library(Seurat)
# suppressPackageStartupMessages( library("grid") )
suppressPackageStartupMessages( library("ggplot2") )
# suppressPackageStartupMessages( library("ggsignif") )
# ======================= COMMAND LINE PARAMETERS SETTING =======================
# ======================= GLOBAL command line parameters setting=================
parser = ArgumentParser(description = "single cell sequencing data manipulating toolsets.",
                        usage = "%(prog)s [global options]" )
parser$add_argument("-i", "--input", type = "character",
             help = "The input exprssion matrix in several possible format.")
parser$add_argument("-f", "--informat", type = "character", default = NULL,
             help = "The format of data object, the possible choices can be:h5seurat,(seurat)rds,(sce)rds, loom.[default: %(default)s]")
parser$add_argument("-o", "--output", type = "character", default = "./",
             help = "the output directory of results."  )
parser$add_argument("-d", "--outformat", type = "character", default = "h5seurat",
             help = "the output format of data object, possible choices:h5seurat,seurat,anndata,sce,CellDataSet(monocle2)[default: %(default)s]")
parser$add_argument("-j", "--ncores", type="integer", default = 10,
             help="the number of CPUs used to improve the performace.[default: %(default)s]")
parser$add_argument("--prefix", type = "character", default = "seurat",
             help = "the prefix of output file without file extension.[default %(default)s]")
parser$add_argument("--assay", type = "character", default = NULL,
             help = "the main assay in data object to use. When it comes to multimodal assay, this is the assay used to initialize the object, all the other assays will merged into it.")
parser$add_argument("--subassay", type = "character", default = NULL,
             help = "[OPTIONAL]the comma separated assays list except the main assay specified by --assay, when it comes to multimodal assay. For monomodal assay, it's NULL as default.")
parser$add_argument("--dataslot", type="character", default="data",
             help="the data slot in the specified assay used for this run, one of 'counts','data' must be provided.[default: %(default)s]")
parser$add_argument("--predicate", type = "character", default = NULL,
             help = "The conditional expression to subset cells used for subtyping.[default: %(default)s]")
parser$add_argument("--update", default= "TRUE", type="character",
             help="whether update the data in the object on disk using the newly produced results. Set this to FALSE when you use this script for subclustering! Only availiable for h5seurat input.[default TRUE]")
subparsers = parser$add_subparsers(help = "subcommands:")
# sce: singlecellexperiement object supported by R packages:scater,scran etc.
# h5: hdf5 formatted molecular quantification from cellranger etc.
# loom: loom format, a specialized hdf5 format.
# h5seurat: the hdf5 formated seurat object.
# h5ad: the format support by scanpy from anndata in python.
# aggr: the result from cellranger aggr
# tenx:the directory of cellranger count/aggr output with sampleid named subdirectory.
# xsv: the raw gene count matrix file, it can be very large. Please make sure the data path is Your_Project/sampleid/sampleid.(tsv|csv).
# cellDataSet: the format for monocle.
# Seurat: the  binary seurat object .rds from the clustering results.
# visium: the output from spaceranger ananlysis of 10X Visium spatial transcriptomics data.", '"""'))
# se: summarizedExperient object in rds format
# htseq: the results from htseq-count
# vdj: the results from cellranger vdj
# smart-seq2:
#
# star: the results from STAR alignment result TO DO

# create the parsers for subcommand create
sub_create = subparsers$add_parser("create",
     help = "make the specified format data object out of the supported input data sources.")
sub_create$add_argument("-s", "--source", type = "character", default = "mtx",
     help = "The source of data, possible choices:h5, mtx, xsv(including BD,tsv and csv), Visium, slideseq.[default: %(default)s]")
sub_create$add_argument("-m", "--metadata", type = "character",
     help = "the sample metadata which must include sample id in this assay design.")
sub_create$add_argument("-x", "--metrics", type = "character", default = "percent.mito",
     help = "the additional QC metrics list to calculate in advance.[default %(default)s]")
sub_create$add_argument("--gcolumn", type = "integer", default = 2,
     help = "Specify which column of genes.tsv or features.tsv to use for feature names.[default %(default)s]")
sub_create$add_argument("--aggr", type = "character", default = "FALSE",
     help = "[OPTIONAL] wether the results derived from cellranger aggr.[default %(default)s]")
sub_create$add_argument("--feature.meta", type = "character", default = NULL,
     help = "[OPTIONAL]the reference genome annotaion file from 10X.")
sub_create$add_argument("--chrom.size", type = "character", default = NULL,
     help = "[OPTIONAL]length of each chromosome of the genome file from 10X.")
sub_create$add_argument("--cell.meta", type = "character", default = "FALSE",
     help = "[OPTIONAL] logical indication wether there is cell annotation file for, 'singlecell.csv' for in ATAC-seq for example.[default: FALSE]")
sub_create$add_argument("--fragment", type = "character", default = "FALSE",
     help = "[OPTIONAL] use the fragment annotion file 'fragments.tsv.gz' in outs directory from cellranger-atac count results for each sample, Only valid for scATAC-seq assay.[default FALSE]")
sub_create$add_argument("--transpose", type = "character", default = "FALSE",
     help = "[OPTIONAL]wether to transpose the count matrix when comes to the cell-feature matrix.[default %(default)s]")
sub_create$add_argument("--gset", type = "character", default = NULL,
     help = "[OPTIONAL]the gmt formated customized genes set file for QC metrics' calculation.")

# create the parsers for subcommand multimodal
sub_multimodal = subparsers$add_parser("multimodal",
     help = "make the specified format data object out of cellranger multimodal assay, currently only scRNA+scATAC.")
sub_multimodal$add_argument("-s", "--source", type = "character", default = "h5",
     help = "The source of multimodal assay data, currently only hdf5 formated files are supported.[default %(default)s]")
sub_multimodal$add_argument("-m", "--metadata", type = "character",
     help = "the sample metadata which must include sample id in this assay design.")
sub_multimodal$add_argument("-x", "--metrics", type = "character", default = "percent.mito",
     help = "the additional QC metrics list to calculate in advance.[default %(default)s]")
sub_multimodal$add_argument("--gcolumn", type = "integer", default = 2,
     help = "Specify which column of genes.tsv or features.tsv to use for feature names.[default %(default)s]")
sub_multimodal$add_argument("--feature.meta", type = "character", default = NULL,
     help = "[OPTIONAL]the reference genome annotaion file from 10X.")
sub_multimodal$add_argument("--cell.meta", type = "character", default = "FALSE",
     help = "[OPTIONAL] logical indication wether there is cell annotation file for, 'singlecell.csv' for in ATAC-seq for example.[default: FALSE]")
sub_multimodal$add_argument("--fragment", type = "character", default = "FALSE",
     help = "[OPTIONAL] use the fragment annotion file 'fragments.tsv.gz' in outs directory from cellranger-atac count results for each sample, Only valid for scATAC-seq assay.[default FALSE]")
sub_multimodal$add_argument("--gset", type = "character", default = NULL,
     help = "[OPTIONAL]the gmt formated customized genes set file for QC metrics' calculation.")

sub_convert = subparsers$add_parser("convert",
     help = "convert the data object from input format to the target format.")
sub_convert$add_argument("--from", type = "character", default = "h5seurat",
     help = "the format of the input data object, choices can be: monocle2(CellDataSet), monocle3(cell_data_set), Seurat, sce(SingleCellExperiment), anndata.")
sub_convert$add_argument("--to", type = "character", default = "",
     help = "the destination output format of the data object, choices can be: monocle2(CellDataSet), monocle3(cell_data_set), Seurat, sce(SingleCellExperiment), anndata..")
# sub_convert$add_argument("--seperateby", type = "character", default = NULL,
#      help = "[OPTIONAL]save the expression matrix in  mtx format like cellranger output for each sample." )

# create the parsers for subcommand subset
sub_subset = subparsers$add_parser("subset",
                    help = "filter the cells using the specified conditions." )
sub_subset$add_argument( "--geneset", type = "character",
                   help = "features/variables to keep in TAB format.")
sub_subset$add_argument("--feature4subset", type = "character",
                  help = "Logical expression on features in matrix indicating cells to keep.Example: 'MSA4>1'.")
sub_subset$add_argument( "--levels", type = "character",
                         help = "The subset of variable levels in variable specified by --group2use.")
sub_subset$add_argument( "--group2use", type = "character",
                         help = "the cell names or annotation column names set for the cell annotation table.")
sub_subset$add_argument( "--low", type = "double", default = NULL,
                         help = "the lower bound of the continious variable specified by --group2use.[default: %(default)s]")
sub_subset$add_argument( "--high", type = "double", default = NULL,
                         help = "the higher bound of the continious variable specified by --group2use.[default: %(default)s]")
sub_subset$add_argument( "--invert", type = "character", default = "FALSE",
                         help = "reverse the selection conditions specified by all other conditions.[default: %(default)s]")
# on stop of running data quanlity control of
sub_qc = subparsers$add_parser("qc", help = "one stop of data control.")
sub_qc$add_argument( "-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
sub_qc$add_argument( "-c", "--filters", type = "character", default = "nFeature_RNA,nCount_RNA,percent.mito",
                help = "the variables used to remove the outliers of cells. The other options can be percent.ribo etc.[default: %(default)s]")
sub_qc$add_argument( "--genes2filter", type = "character", default = NULL,
                help = "the genelist to filter.")
sub_qc$add_argument( "--QC", type = "character", default = "TRUE",
                help = "running data quanlity control.[default: %(default)s]")
sub_qc$add_argument( "-x", "--mincell4gene", type="double", default = 0.01,
                help="the minimium cell number one gene detected.If the value is less than 1, it is a proportion, otherwise a integerial cell number.[default: 10]")
sub_qc$add_argument( "-u", "--rlm.xy", type = "character", default = NULL,
                help = "[OPTIONAL]using the robust linear model of variables, for example nCount_RNA:nFeature_RNA, to remove the outliers of cells.[default: NULL]")
sub_qc$add_argument( "--cut.1", type = "character", default = "median",
                help = "the method to determine the center of an array, here refering to the median or mean of the QC metric.[default: %(default)s]")
sub_qc$add_argument( "--cut.2", type = "character", default = "mad",
                help = "the method to find the difference unit to the data center, here refering to median, sd or mad.[default: %(default)s]")
sub_qc$add_argument( "-n", "--nfold", type="double", default = 2.0,
                help="the fold of intervals(sd for mean, mad for median, median for median) for parameters specified by --filters determine the outlier threshold by +/- n*cut.2.[default:2.0]")
sub_qc$add_argument( "-l", "--lower", type="character", default = "200,2000,0",
                help="the lower bounds list for the parameters specified by --filters.[default: %(default)s]" )
sub_qc$add_argument( "-L", "--upper", type="character", default = NULL,
                help="the upper bounds list for the parameters specified by --filters.If not specified, it will be determined by the parameter --cut.1, --cut.2 and -n automatically." )
sub_qc$add_argument("-m", "--normmeth", type="character", default = "LogNormalize",
                help="the method to normalize the raw counts. Choices can be: sctransform, LogNormalize, scran, CR, CLR,logTF-IDF, TF-logIDF, logTF-logIDF, IDF etc. For feature-barcoding/cite-seq, CLR is recommended. For scRNA-seq, sctransform is recommended. Notice that if sctransform used, the default assay should be changed to SCT automatically in the later analysis. For ATAC assay, logTF-IDF id recommended.")
sub_qc$add_argument("-z", "--features2filter", type = "character", default = NULL,
                help = "[OPTIONAL]the file of specified feature list with 'gene' as header to remove from the features-cell matrix.[default: NULL]")
sub_qc$add_argument("-v", "--pointsize", type = "double", default = 0.1,
             help = "the size for each point in QC metrics vlnplot plot. Set 0 for point-freee vlnplot.")
sub_qc$add_argument("--nvfeatures", type = "double", default = 2000,
                help = "[OPTIONAL]the number of top variable features to keep for RNA-seq or the minimum percentile(0~1), for example 0.95, for ATAC-seq .")
sub_qc$add_argument("--rmdoublets", type = "character", default = "FALSE",
                            help = "remove the doublet cells.[default: %(default)s]")
sub_qc$add_argument("--method", type = "character", default = "scrublet",
                            help = "the method used to detect doublets, choices: scrublet, doubletfinder.[default: %(default)s]")
sub_qc$add_argument("--ident", type = "character", default = "clusters",
                            help = "[OPTIONAL]ONLY AVAILABLE for doubletfinder,the name of cell group annotation.")

## on stop of running data quanlity control of
#sub_qc = subparsers$add_parser("qc", help = "one stop of data control.")
#sub_qc$add_argument( "-x", "--mincell4gene", type="double", default = 0.01,
#                help="the minimium cell number one gene detected.If the value is less than 1, it is a proportion, otherwise a integerial cell number.[default: 10]")
#sub_qc$add_argument( "-u", "--rlm.xy", type = "character", default = NULL,
#                help = "[OPTIONAL]using the robust linear model of variables, for example nCount_RNA:nFeature_RNA, to remove the outliers of cells.[default: NULL]")
#sub_qc$add_argument( "--cut.1", type = "character", default = "median",
#                help = "the method to determine the center of an array, here refering to the median or mean of the QC metric.[default: %(default)s]")
#sub_qc$add_argument( "--cut.2", type = "character", default = "mad",
#                help = "the method to find the difference unit to the data center, here refering to median, sd or mad.[default: %(default)s]")
#sub_qc$add_argument( "-n", "--nfold", type="double", default = 2.0,
#                help="the fold of intervals(sd for mean, mad for median, median for median) for parameters specified by --filters determine the outlier threshold by +/- n*cut.2.[default:2.0]")
#sub_qc$add_argument( "-c", "--filters", type = "character", default = "nFeature_RNA,nCount_RNA,percent.mito",
#                help = "the variables used to remove the outliers of cells. The other options can be percent.ribo etc.[default: %(default)s]")
#sub_qc$add_argument( "-l", "--lower", type="character", default = "200,2000,0",
#                help="the lower bounds list for the parameters specified by --filters.[default: %(default)s]" )
#sub_qc$add_argument( "-L", "--upper", type="character", default = NULL,
#                help="the upper bounds list for the parameters specified by --filters.If not specified, it will be determined by the parameter --cut.1, --cut.2 and -n automatically." )
#sub_qc$add_argument("-m", "--normmeth", type="character", default = "LogNormalize",
#                help="the method to normalize the raw counts. Choices can be: sctransform, LogNormalize, scran, CR, CLR,logTF-IDF, TF-logIDF, logTF-logIDF, IDF etc. For feature-barcoding/cite-seq, CLR is recommended. For scRNA-seq, sctransform is recommended. Notice that if sctransform used, the default assay should be changed to SCT automatically in the later analysis. For ATAC assay, logTF-IDF id recommended.")
#sub_qc$add_argument("-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
#                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
#sub_qc$add_argument("-z", "--features2filter", type = "character", default = NULL,
#                help = "[OPTIONAL]the file of specified feature list with 'gene' as header to remove from the features-cell matrix.[default: NULL]")
#sub_qc$add_argument("-v", "--pointsize", type = "double", default = 1,
#             help = "the size for each point in QC metrics vlnplot plot. Set 0 for point-freee vlnplot.")
#sub_qc$add_argument("--nvfeatures", type = "double", default = 2000,
#                help = "[OPTIONAL]the number of top variable features to keep for RNA-seq or the minimum percentile(0~1), for example 0.95, for ATAC-seq .")
#sub_qc$add_argument("--subset", type = "character", default = "TRUE",
#                help = "[OPTIONAL]logical indication wether to subset the data object according to threshold specified by user.[default: TRUE]")

# normalize the raw data before downstream data analysis
sub_normalize = subparsers$add_parser("normalize", help = "normalize the raw data.")
sub_normalize$add_argument("-m", "--nmethod", type = "character", default = "sct",
              help = "the normalization method to choose from: sct, LogNormalize, scran, cr,clr for single cell data.")
sub_normalize$add_argument("-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
sub_normalize$add_argument( "-s", "--scale-factor", default = 10000, type = 'integer',
                help = "Sets the scale factor for cell-level normalization.[default: %(default)s]" )
sub_normalize$add_argument("--sct-method", default = "glmGamPoi", type = 'character',
                help = "the distribution type used to fit generalized linear models of each gene count against the sequencing depths, choices:poisson, glmGamPoi(faster).[default: %(default)s]")
sub_normalize$add_argument( "--margin", default = NULL, type = 'integer',
                help = "If performing CLR normalization, normalize across features (1) or cells (2)." )
sub_normalize$add_argument("--model", type = "character", default = "linear",
          help = "Use a linear model or generalized linear model (poisson, negative binomial) for the regression. Options are 'linear' (default), 'poisson', and 'negbinom'")
sub_normalize$add_argument("--use-umi", type = "character", default = "FALSE",
          help = "Regress on UMI count data. Default is FALSE for linear modeling, but automatically set to TRUE if model.use is 'negbinom' or 'poisson'")
sub_normalize$add_argument("--block-size", type = "integer", default = 1000,
          help = "Default size for number of features to scale at in a single computation. Increasing block.size may speed up calculations but at an additional memory cost.")

# cluster the data
sub_cluster = subparsers$add_parser("bclust", help = "one stop run of data dimension reduction and clustering.")
sub_cluster$add_argument("-t", "--components", type="integer", default=NULL,
             help="the appropriate number of dimensions for primary reduction. Recommendations:pca:30,mnn:10[default: %(default)s]")
sub_cluster$add_argument("-p", "--perplexity", type="integer", default=30,
             help="The value of the perplexity only availiable for tSNE.[default: %(default)s]")
sub_cluster$add_argument("-m", "--metadata", type="character", default = NULL,
             help="[OPTIONAL]the additional sample metadata which must include sample id in this assay design.")
sub_cluster$add_argument("-c", "--clusteringuse", type="character", default = "snn",
             help="the only supported clustering algorithms currently:snn,louvain,leiden. For other methods, use subcommand 'clusterx'." )
sub_cluster$add_argument("-r", "--resolution", type = "double", default = 0.4,
             help = "vaule used to set the resolution of cluster distiguish, use a value above(below)1.0 if you want to obtain a larger(smaller) number of communities.[default: %(default)s]")
sub_cluster$add_argument("-s", "--pointsize", type = "double", default = NULL,
             help = "[OPTIONAL]the point size in the plot.")
sub_cluster$add_argument("-b", "--batchid", type = "character", default = NULL,
             help = "[OPTIONAL]the batch information column name of sample in the metadata.")
sub_cluster$add_argument("--reduct1", type = "character",default="pca",
             help="the primary dimension reduction results used for clustering. Now ica,cca,pca,lsi,mnn,tsne,harmony,Flt-SNE,UMAP,swne,diffusion,phate,fa2 are supported.[default: %(default)s]")
sub_cluster$add_argument("--reduct2", type = "character",default=NULL,
             help="the secondary reduction method usually used to embed community. Now tsne,Flt-SNE,UMAP,swne,diffusion,phate,fa2 are supported. If NULL supplied, NO secondary reduction will be carried out.[default: NULL]")
sub_cluster$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell cluster, customecol2 as default. Choices: customecol2:50;blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20, paired:12, purplegray12:12")
# sub_cluster$add_argument("--no-update", dest = "update", action="store_false",
#              help="produce new data object on disk. Only availiable for h5seurat input.")
sub_cluster$add_argument("--rerun", default="FALSE", type = "character",
             help="Rerun the primary reduction in case of parameter changes.[default FALSE]")
# sub_cluster$add_argument("--no-rerun", dest = "rerun", action="store_false",
#              help="NO rerun the primary reduction.")

# create the parser for subcommand celltyping
# the dataslot here is used to specifiy which data slot to use when celltyping
sub_celltype = subparsers$add_parser("celltyping", help = "find the celltype for each cell in data object.")
sub_celltype$add_argument("-c","--builtinref", type = "character",
             help = "one or more builtin reference data object name in SummarizedExperiment/SingleCellExperiment object.")
sub_celltype$add_argument("-r","--customref", type = "character",
             help = "One or more SummarizedExperiment/SingleCellExperiment data object containing log-transformed matrix used as non-built-in reference.")
sub_celltype$add_argument("--annolevel", type = "character", default=NULL,
             help = "cell identities annotation column in reference data for each cell in test data. If set, annotation is performed on the cluster level, otherwise it defaults to per-cell annotation.")
sub_celltype$add_argument("--usecluster", type = "character", default = "FALSE",
             help = "wether to predict identitiy for each cluster of test data rather than single cell.")
sub_celltype$add_argument("--demethod", type = "character", default = "classic",
             help = "String specifying how DE genes should be detected between pairs of labels in ref data. Choices can be:classic,wilcox and t.[default: %(default)s].")
sub_celltype$add_argument("-v", "--pointsize", type = "double", default = NULL,
             help = "the size for each point in scatter plot.")
sub_celltype$add_argument("-n", "--topn", type = "integer", default = 25,
             help = "the top number of reference cell type score for each test cell to visulize on heatmap.")
sub_celltype$add_argument("--colorschema", type = "character", default = NULL,
             help = "the default color schema mapping for valus in each heatmap cell. The format:low, middle, high.")
sub_celltype$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell types, customecol2 as default. Choices: blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20, paired:12, purplegray12:12")
sub_celltype$add_argument("--reduct", type = "character", default = "umap",
             help = "[OPTIONAL]the reduction results used to embedding the celltypeing results.[default: %(default)s]")
sub_celltype$add_argument("--species", type = "character", default = "human",
             help = "[OPTIONAL]the organism both test and reference data derived.[default: %(default)s]")


# create the parsers for subcommand merge
sub_merge = subparsers$add_parser("merge",  help = "merge data object")
sub_merge$add_argument( "--toadd", type = "character",
             help = "one or more of object list to merge into the target object.")
sub_merge$add_argument( "--adformat", type = "character",
             help = "The format of input expression matrix to add")
sub_merge$add_argument( "--mergedata", type = "character",
             help = "logical string T/F to indicate wether to merge the data slot")

# create the parsers for subcommand summarize
sub_summ = subparsers$add_parser("summarize", help = "summarized statistics for clustering results")
sub_summ$add_argument( "-c", "--groupby", type = "character", default = "clusters",
             help = "[OPTIONAL]visualize cell metadata by coloring cells in different color according to cell clustering metadata.[default: %(default)s].")
sub_summ$add_argument( "-b", "--facetby", type = "character", default = NULL,
             help = "[OPTIONAL]visualize cells in seperate plot split by this groupping variable, only 2D supported.")
sub_summ$add_argument( "-s", "--pointsize", type = "double", default = NULL,
             help = "[OPTIONAL]the point size in the plot.[default: %(default)s]")
sub_summ$add_argument( "-k", "--dims", type = "integer", default = 2,
             help = "[OPTIONAL]the 2D/3D of the plot.Currently 3D plot is only support in plotly style.[default: %(default)s]")
sub_summ$add_argument( "--reduct", type = "character", default = "umap",
             help = "[OPTIONAL]the previous calculated reduction result used in the scatter plot.[default: %(default)s]")
sub_summ$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell groups, customecol2 as default. Choices:blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20, paired:12, purplegray12:12")
sub_summ$add_argument( "--dosummary", type = "character", default = "TRUE",
             help = "wether to plot the summary statistics of cells clustering.[default: TRUE]")


# create the parsers for subcommand split
sub_split = subparsers$add_parser("split", help = "split the object according to the cell metadata.")
sub_split$add_argument("--splitby", type = "character", default = "ident",
                       help = "the cell annotation column name.If NOT supplied, %(default)s will be used as default!")


sub_findneighbor = subparsers$add_parser("findneighbor", help = "only find the clusters in the input data")
sub_findneighbor$add_argument( "-k", "--k_param", default = 20, type = 'integer',
    help = "Defines k for the k-nearest neighbor algorithm" )
sub_findneighbor$add_argument( "--nn_method", default = 'rann', type = 'character',
    help = "Method for nearest neighbor finding. Options include: rann (default), annoy(faster)" )
sub_findneighbor$add_argument( "-a", "--dist_metric", type = 'character', default = "euclidean",
    help = "Distance metric. Options include: euclidean (default), cosine, manhattan, and hamming" )
sub_findneighbor$add_argument( "--graph_name", type = 'character', default = NULL,
    help = "Name of graph to use for the clustering algorithm." )
sub_findneighbor$add_argument( "--force_recalc", type = "character", default = "FALSE",
    help = "Force recalculation of SNN" )
sub_findneighbor$add_argument( "--reduction", type = 'character', default = "pca",
    help = "one or more reductions to use as input for building the (S)NN for mono-modal or multi-modual assays." )
# sub_findneighbor$add_argument( "-f", "--features", default = NULL, type = 'character',
#     help = "Comma-separated list of genes to use for building SNN. Alternatively, text file with one gene per line." )
# sub_findneighbor$add_argument( "--reduction", default = NULL, type = 'character',
#     help = "one or more Reduction  to use as input for building the SNN" )
sub_findneighbor$add_argument( "--dims", default = "1:15", type = 'character',
    help = "Dimensions of reduction to use as input. A comma-separated list of the dimensions to use in construction of the SNN graph." )

# create the parsers for subcommand removeEmptyDrops
sub_removeEmpty = subparsers$add_parser("rmambients", help = "remove the empty droplet using DropletUitls")
sub_removeEmpty$add_argument("--fdr", type = "double", default = 0.25,
             help = "the significance level for a cell to be identified as an empty droplet.")
sub_removeEmpty$add_argument("--iters", type = "integer", default = 1000,
             help = "the iteration to be used in calculation.")

# calculate the score of gene modules
sub_score = subparsers$add_parser("score", help = "calculate the gene module score")
sub_score$add_argument("--name", type = "character", default = NULL,
        help = "the  name of internal gene set. Choices can be:Macosko_mouse, Macosko_human, Jeny2020")
sub_score$add_argument("--gmt", type = "character", default = NULL,
        help = "the gene sets in gmt format for calculation.")
sub_score$add_argument("--min.size", type = "integer", default = 5,
        help = "the minimal number of genes in each gene set.[default: %(default)s]")
sub_score$add_argument("--plot", type = "character", default = NULL,
        help = "methods used to visualize the gene module score of each cell. Choices:NULL,vlnplot, featureplot. [default: NULL] no plot")
sub_score$add_argument("-g", "--groupby", type = "character", default = "clusters",
        help = "[OPTIONAL]The grouppinig variable in the metadata for separate the cells to visulize marker genes.")
sub_score$add_argument("--dodge", type = "character", default = "FALSE",
        help = "[OPTIONAL]visualize the feature between the contrast groups separately for each level in variable specified by --groupby.")
sub_score$add_argument("-y", "--splitby", type = "character", default = NULL,
        help = "[OPTIONAL]the variable in the metadata used to split the graph by the variable levels to comparing the module difference in different levels.")
sub_score$add_argument("--ccolors", type = "character", default = "grey,red",
        help = "[OPTIONAL]the name of customized continious color palatte, recommandations:spectral, solar_extra,flame_light or color scale used to map the continious expression value for feature plot or dotplot,format:low_color,high_color.[default: %(default)s]")

# create the parsers for subcommand fetech
sub_fetch = subparsers$add_parser("fetch", help = "Retreives data (feature expression, PCA scores, metrics, etc.)")
# for a set of cells.A table with cells as rows and cellular data as columns returns.
sub_fetch$add_argument("--vars",
            help = "comma seperated List of all variables to fetch, use keyword ident to pull identity classes.")
sub_fetch$add_argument("--header",
            help = "[OPTIONAL]change the header of the output table if specified. Notice that the first column is always the cell barcode.")

# create the parsers for subcommand downsample
sub_downsample = subparsers$add_parser("downsample", help = "downsample the exppression matrix in case of too many cell and scarcely disequal cell numbers in each sample")
sub_downsample$add_argument("--targetN", type = "integer",
              help = "the number of cell to keep after downsample.")
sub_downsample$add_argument("--usePCA", type = "character", default = "TRUE",
              help = "logical parameter indicating wether to use fbpca during before downsample.[default: TRUE]")
sub_downsample$add_argument("--subsampleby", type = "character",
             help = "radom subsample by the specified group using the specified ratio,example:'clusters:0.5'.")


sub_vis = subparsers$add_parser("visualize", help = "visualize the specified features.")
sub_vis$add_argument("-l", "--markers",type ="character",
        help="the file of marker genes table to be visulized.")
sub_vis$add_argument("-n", "--topn", type="integer", default = 10,
        help = "the number of top markers for each cluster to visualizse.")
sub_vis$add_argument("-c", "--topby", type = "character", default = "gene_diff",
        help="the column used to pick top n marker genes.The option can be one of the column in the input marker genes table.")
sub_vis$add_argument("-x", "--extraGene", type = "character", default = NULL,
        help = "[OPTIONAL]The extra gene list of interest to visualize specified by the user.[default: NULL]")
sub_vis$add_argument("-m", "--vismethod",type= "character",default="vlnplot,featureplot",
        help = "the visulization methods for the marker genes. Choices can be: ridgeplot,vlnplot,dotplot,featureplot,boxplot.")
sub_vis$add_argument("--pvalue",type= "character",default = NULL,
        help = "[OPTIONAL]use like GROUP1:GROUP2+GROUP2:GROUP3 to add pvalue on vlnplot or boxplot.")
sub_vis$add_argument("-g", "--groupby", type = "character", default = "clusters",
        help = "[OPTIONAL]The grouppinig variable in the metadata for separate the cells to visulize marker genes.")
sub_vis$add_argument("--dodge", type = "character", default = "FALSE",
        help = "[OPTIONAL]visualize the feature between the contrast groups separately for each level in variable specified by --groupby.Only valid for violin plot!")
sub_vis$add_argument("-y", "--splitby", type = "character", default = NULL,
        help = "[OPTIONAL]the variable in the metadata used to split the graph by the variable levels to comparing the gene expression difference in different levels.[default: NULL]")
sub_vis$add_argument("--ccolors", type = "character", default = "grey,red",
        help = "[OPTIONAL]the name of customized continious color palatte, recommandations:spectral, solar_extra,flame_light or color scale used to map the continious expression value for feature plot or dotplot,format:low_color,high_color.[default: %(default)s]")
sub_vis$add_argument("--vcolors", type = "character", default = "customecol2",
        help = "[OPTIONAL]the name of customized discrete color used to map to the cell groupping variable.[default: %(default)s]Choices:blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20,Buen:17,UKBB:18,TF1:17,paired:12")
sub_vis$add_argument("-s", "--pointsize", type = "double", default = 0.1,
        help = "[OPTIONAL]the point size in the plot.")
# sub_vis$add_argument("--sample_ratio", type = "double", default = 0.6,
#         help = "[OPTIONAL]the ratio of random subsample for each group when drawing heatmap.")
sub_vis$add_argument("--reduct", type = "character", default = "umap",
        help = "[OPTIONAL]the previous calculated reduction result used in the featureplot,.")
sub_vis$add_argument("-a", "--alpha2use", type = "double", default = 0,
        help = "[OPTIONAL]the opacity of the pooints on the violin plot.")
sub_vis$add_argument("--xlab", type = "character", default = "TRUE",
        help = "[OPTIONAL]show xlab or not")

sub_markers = subparsers$add_parser("findallmarkers", help = "find markers between all groups.")
sub_markers$add_argument( "--min_pct1", "-t", type = "double", default = 0.5,
       help ="the minimium ratio of cells expressing one specific gene in a cluster.[default: %(default)s]")
sub_markers$add_argument( "--max_pct2", "-T", type = "double", default = 0.5,
       help ="the maximiium ratio of cells expressing one specific gene in all other clusters.[default: %(default)s]")
sub_markers$add_argument( "--pct_fold", "-c", type = "double", default = 2,
       help ="the minimiu fold of pct1 for gene in a specific cluster against pct2 for all other cluster.[default: %(default)s]")
sub_markers$add_argument( "--topn_marker","-N", type = "integer",default = 10,
       help = "the maximium number of ranked marker genes on the top for each cluster.[default: %(default)s]")
sub_markers$add_argument( "--avg_log2FC","-k", type = "double", default = 1,
       help = "The average log2FC of the gene UMI count in its cluster against the all other clusters.[default: %(default)s]")
sub_markers$add_argument( "--pvalue","-p", type = "double", default = 0.05,
       help = "the P-value of the gene differential expression.[default: %(default)s]")
sub_markers$add_argument( "--cluster_name", "-n", type = "character", default = NULL,
       help = "the name of groupping column from clustering result metadata used to find markers. The example can be tsne.2D.res.1.")
sub_markers$add_argument( "--FDR","-q", type = "double", default = 0.1,
       help = "the FDR of the gene differential expression.")
sub_markers$add_argument( "--strict","-s", type = "character", default = "FALSE",
       help = "whether to use strict mode, using all the filtering options, to find markers. Notice that, this may result in no markers remain for some clusters.")
sub_markers$add_argument( "--test","-e", type = "character", default = "wilcox",
       help = "test methods used to cell markers.[default: %(default)s] Options are: wilcox,presto,venice, t, bimod,poisson, negbinom, MAST, DESeq2, DESeq2LRT,limma, edgeR.")
# 'wilcox' : Wilcoxon rank sum test (default).
# 'presto' : performace improved Wilcoxon rank sum test for big data.
# 'venice' : package from bioTuning with function VeniceAllMarkers imtating the FindAllMarkers in Seurat but much faster.")
# 't' : Student\'s t-test.
# 'bimod' : Likelihood-ratio test for single cell gene expression, (McDavid et al., Bioinformatics, 2013).
# 'poisson' : Likelihood ratio test assuming an underlying poisson distribution. Use only for UMI-based datasets.
# 'negbinom' : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets.
# 'MAST' : GLM-framework that treates cellular detection rate as a covariate (Finak et al, Genome Biology, 2015).
# 'DESeq2' : DE based on a model using the negative binomial distribution (Love et al, Genome Biology, 2014).


# create the parsers for subcommand update
sub_update = subparsers$add_parser("update",
          help = "update the main data object using annotation from other data object or external info.")
sub_update$add_argument("--admeta", type = "character",
          help = "the additional metadata which includes any groupping design in this assay.")
sub_update$add_argument("--annlevel", type = "character", default = "sample",
          help = "the annotation level,sample or cell is supported.")
sub_update$add_argument("--recode", type = "character", default = NULL,
          help = "rename the level id in specified groups in the file with each column corresponding to header in the object metadata and column element format as from:to.")
# sub_update$add_argument("--adfeatures", type = "character",
#           help = "the additional metadata of genes in the object.")


sub_write10x = subparsers$add_parser("write10x", help = "save the data object into the format from 10X Genomics.")
sub_write10x$add_argument("--split.by", "-x", type = "character", default = NULL,
          help = "the groupping variable of cells used to split the data object.[default: %(default)s]")
sub_write10x$add_argument("--overwrite", type = "character", default = "TRUE",
          help = "wether to overwrite the existed data object.[default: %(default)s]")
sub_write10x$add_argument("--version", "-v", type = "character", default = "3",
          help = "the version of cellranger to format the output to.[default: %(default)s]")
sub_write10x$add_argument("--h5", type = "character", default = "FALSE",
          help = "Wether to save the count matrix in hdf5 format defined by 10X Genomics.[default: %(default)s]")

sub_findhvg = subparsers$add_parser("findhvg", help = "features extraction of highly variable features.")
sub_findhvg$add_argument("--select-method", type = "character", default = "vst",
          help = "methods to choose top variable features. Choices:vst, mean.var.plot, dispersion and markvariogram, moransi sepecifi for spatial data.[default: %(default)s]")
sub_findhvg$add_argument("--loess-span", type = "double", default = 0.3,
          help = "(vst only)Loess span parameter used when fitting the variance-mean relationship.[default: %(default)s] Only used when selection method is set to 'dispersion' or 'vst'.")
sub_findhvg$add_argument("--nfeature", type = "integer", default = 2000,
          help = "Number of features to select as top variable features.[default: %(default)s]")

sub_dimreduce = subparsers$add_parser("dimreduce", help = "dimension reduction.")
sub_dimreduce$add_argument("-t", "--components", type="integer", default=NULL,
             help="the appropriate number of dimensions for primary reduction. Recommendations:pca:30,mnn:10[default: %(default)s]")
sub_dimreduce$add_argument( "--perplexity", "-p", type="integer", default=30,
           help="The value of the perplexity used for tSNE")
sub_dimreduce$add_argument( "--rerun", type="character", default = "FALSE",
           help="[OPTIONAL]wether to rerun the reduction to overwrite the previous results.[default: FALSE]")
sub_dimreduce$add_argument( "--reduct1", type = "character",default=NULL,
           help="[OPTIONAL]the primary reduction methods whose results can be used as input for secondary reduction. The supported methods can be one of the followings: ica, cca, pca, rpca, lsi, svd, mnn, harmony, tsne, flt-tsne, umap, diffusion.")
sub_dimreduce$add_argument( "--reduct2",type = "character",default="tsne",
           help="one or more of the scondary dimension reduction methods used for this run. the options can be tsne, flt-sne, umap, duffusion, swne. That is to say not all the primary redcution method can used as scondary one.")
sub_dimreduce$add_argument( "--batchid", type = "character", default = NULL,
             help = "[OPTIONAL]the batch information column name of sample in the metadata.")


sub_clusterx = subparsers$add_parser("clusterx", help = "universal interface of clustering methods")
sub_clusterx$add_argument("--algorithm", type="character", default = "snn",
             help="the only supported clustering algorithm currently:snn,louvain,leiden. For other methods, use subcommand 'clusterx'." )
sub_clusterx$add_argument("-r", "--resolution", type = "double", default = 0.4,
             help = "vaule used to set the resolution of cluster distiguish, use a value above(below)1.0 if you want to obtain a larger(smaller) number of communities.[default: %(default)s]")
sub_clusterx$add_argument( "--graphid", type = "character", default = NULL,
             help = "the graph name used to find communities.[default: NULL]")
sub_clusterx$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell cluster, customecol2 as default. Choices:blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20, paired:12, purplegray12:12")
sub_clusterx$add_argument("-s", "--pointsize", type = "double", default = 0.5,
             help = "[OPTIONAL]the point size in the plot.")

sub_diffexp = subparsers$add_parser("diffexp", help = "differential test between specified groups.")
sub_diffexp$add_argument("-x", "--design", type = "character", default = NULL,
          help = "The group design for cell clusters or samples to make differential expression analysis.")
sub_diffexp$add_argument("-M", "--addition_metadata", type="character", default = NULL,
          help="[Optional]additional metadata for each sample which includes sample id and additional sample groupping info.")
sub_diffexp$add_argument("-c","--contrast", type = "character",default = NULL,
          help = "[Optional]levels of a factor used to compare with for final differenetial results. The format is Factor:interesting_levle:reference_level.")
sub_diffexp$add_argument("-k", "--FC", type = "double", default = 1,
          help = "The average FC of the gene UMI count in its cluster against the all other clusters.")
sub_diffexp$add_argument("-p", "--pvalue", type = "double", default = 0.05,
          help = "the P-value of the gene differential expression.",metavar = "P-value")
sub_diffexp$add_argument("--fdr","-q", type = "double", default = NULL,
          help = "the FDR of the gene differential expression.",metavar = "FDR")
sub_diffexp$add_argument("--test","-e", type = "character", default = "wilcox",
          help = "the test methods used to find differential expressed genes between specified group levels.[default: %(default)s] Options are:wilcox,presto,venice,limma,roc,t,bimod,poission negbinom,scde,MAST,DESeq2,DESeq2LRT,edgeR.")

# add_annotation
sub_annotation = subparsers$add_parser("annotation", help = "add annotation for genelist.")
sub_annotation$add_argument("-g","--genelist", type = "character", default = NULL,
       help = "The gene list file ")
sub_annotation$add_argument("-a","--anno", type = "character", default = NULL,
       help = "The gene annotation file: gene_annotation.xls")
# changecelltype
sub_changecelltype = subparsers$add_parser("changecelltype", help = "add annotation for genelist.")
sub_changecelltype$add_argument("-c","--celltype", type = "character", default = NULL,
       help = "The celltype file ")
sub_changecelltype$add_argument("-b","--barcode", type = "character", default = FALSE,
       help = "[OPTIONAL]The celltype file base on barcode or not")
sub_changecelltype$add_argument("--palette", type = "character", default = "customecol2",
       help = "The color scheme")
sub_changecelltype$add_argument("-r","--reduct", type = "character", default = "umap",
       help = "The reduction to visualize")
sub_changecelltype$add_argument("-C","--cluster", type = "character", default = "clusters",
       help = "The Columns used to modify cell types")



sub_removedbls = subparsers$add_parser("rmdoublets", help = "remove doublets.")
sub_removedbls$add_argument("--dbl_rates", type = "double", default = 0.06,
                            help = "the expected doublets rate in each sample.")
sub_removedbls$add_argument("--method", type = "character", default = "scrublet",
                            help = "the method used to detect doublets, choices: scrublet, doubletfinder.[default: %(default)s]")
sub_removedbls$add_argument("--subset", type = "character", default = "TRUE",
                            help = "logical indication of wether to subset the data object for only singlets.[default: TRUE]")
sub_removedbls$add_argument("--ident", type = "character", default = "clusters",
                            help = "[OPTIONAL]ONLY AVAILABLE for doubletfinder,the name of cell group annotation.")

sub_refd = subparsers$add_parser("preparerefd", help = "prepare the single cell reference data appropriate for SingleR.")

sub_rmbatch = subparsers$add_parser("rmbatch", help = "remove batches among data sets.")

# create the parsers for subcommand metacell
sub_metacell = subparsers$add_parser("metacell", help = "produce cell count matrix of metacell")

sub_callpeak = subparsers$add_parser("callpeak", help = "call peak for each group of cell for scATAC-seq")
sub_callpeak$add_argument("--groupby", type = "character", default = "clusters",
                          help = "Grouping variable to use. If set, peaks will be called independently on each group of cells and then combined. Note that to call peaks using subsets of cells we first split the fragment file/s used, so using a grouping variable will require extra time to split the files and perform multiple MACS peak calls, and will store additional files on-disk that may be large. Note that we store split fragment files in the temp directory, and if the program is interrupted before completing these temporary files will not be removed. If NULL, peaks are called using all cells together (pseudobulk).")
sub_callpeak$add_argument("--mac2", type = "character", default = NULL,
                          help = "Path to MACS program. If NULL, try to find MACS automatically.")
sub_callpeak$add_argument("--broad", type = "character", default = "FALSE",
                          help = "whether to Call broad peaks (--broad parameter for MACS).")
sub_callpeak$add_argument("--ident", type = "character", default = NULL,
                          help = "List of identities to include if grouping cells (only valid if also setting the group.by parameter). If NULL, peaks will be called for all cell identities.")
sub_callpeak$add_argument("--combine", type = "character", default = NULL,
                          help = "Controls whether peak calls from different groups of cells are combined using GenomicRanges::reduce when calling peaks for different groups of cells (group.by parameter). If FALSE, a list of GRanges object will be returned. Note that metadata fields such as the p-value, q-value, and fold-change information for each peak will be lost if combining peaks.")
sub_callpeak$add_argument("--chunk", type = "integer", default = 2000,
                          help = "Number of regions to load into memory at a time, per thread. Processing more regions at once can be faster but uses more memory.")

# create the parsers for subcommand integrate
sub_transfer = subparsers$add_parser("transfer", help = "integrate multiple data objects.")
sub_transfer$add_argument("--algrithms", type = "character", default = "seurat",
          help = "the algrithms used integrate the different data objects, choices: seurat, harmony, liger, conos.")


# create the parsers for subcommand impute
sub_impute = subparsers$add_parser("impute", help = "impute the missing values in count matrix.")
sub_impute$add_argument("--method", type = "character", default = "magic",
          help = "the method used to impute the sparse matrix.[default: %(default)s]")
sub_impute$add_argument("--slot", type = "character", default = "counts",
          help = "the name of the matrix to impute of the specified assay")


# create the parsers for subcommand summary
sub_summary = subparsers$add_parser("summary", help = "print the summary statitics of data object")

# run copy number variation inference useing infercnv
sub_infercnv = subparsers$add_parser("infercnv", help = "infer copy number variation from single cell expression raw counts.")
sub_infercnv$add_argument("-g", "--gene_order", type = "character",
             help = "[OPTIONAL]The tab-delimited gene_order_file of the positions for each gene along each chromosome without header, with columns: chromosome, start, and stop position")
sub_infercnv$add_argument("-t", "--malignant", type = "character",
             help = "the cell type name to be assumed as cancer cells")
sub_infercnv$add_argument("-l", "--celltype", type = "character",
             help = "the cell type annotation column name to use in seurat metadata.")
sub_infercnv$add_argument("-u", "--mode", type = "character", default = "subclusters",
             help = "Grouping level for image filtering or HMM predictions. Options can be:samples: fastest, but subclusters is ideal. subclusters: detect the subclusters  of tumor")
sub_infercnv$add_argument("-m", "--clusting2use", type = "character", default = "ward.D2",
             help = "the hierarchical clustering methods of cells to use. Valid choices are: 'ward.D', 'ward.D2', 'single', 'complete', 'average', 'mcquitty', 'median', 'centroid'.")
sub_infercnv$add_argument("-r", "--refgroup", type = "character",
             help = "a comma seperated list containing the classifications of the reference (normal) cells to use for infering cnv. If the normal reference cell is supplied from customized source, all the reference cell type will be named as 'normal'.")
sub_infercnv$add_argument("--refexp", type = "character",
             help = "[OPTIONAL]the reference (normal) cells expression count matrix for inferring cnv.")
sub_infercnv$add_argument( "--gtf", "-z", type = "character",
             help = "the exact gtf file for the alignment for this project.")
# make_option( c("--chr2exclude", "-x"), type = "character", default = "chrM",
#     help = "list of chromosomes in the reference genome annotations that should be excluded from analysis."),
sub_infercnv$add_argument( "--cutoff", "-c", type = "double", default = 0.1,
            help = "min average read counts per gene among reference cells. cutoff=1 works well for Smart-seq2, and cutoff=0.1 works well for 10x Genomics.")
sub_infercnv$add_argument( "--doHMM",type="character", default = "FALSE",
            help="wether to using HMM when predicting the CNV for each cell. If no CNV gene prediction needed, Set it False to save time." )
sub_infercnv$add_argument("--do-cnvlevel", type = "character", default = "FALSE",
            help = "wether to calculate the cnv level for each cell.")
sub_infercnv$add_argument( "--pval","-p",type="double", default = 0.05,
            help="max p-value for defining a significant tumor subcluster." )

sub_vdj = subparsers$add_parser("vdj", help = "parse the output of cellranger vdj to integrate.")
sub_vdj$add_argument("--vdj", type = "character", default = "./",
       help = "the directory of 10X cellranger vdj results directory with each sample as subdirectory or the directory with file filtered_contig_annotations.csv,clonotypes.csv, all_contig_annotations.json,all_contig.fasta.")
sub_vdj$add_argument("--metadata", "-m", type="character", default = NULL,
       help="the sample metadata which must include sample id in this assay design.")
sub_vdj$add_argument("--type", "-t", type="character", default = NULL,
       help="the type of immunological cell receptor: TCR or BCR.")
sub_vdj$add_argument("--seurat", "-s", type="character", default = NULL,
       help="add the clonotype annotation to the seurat as an assay.")
sub_vdj$add_argument("--quant.use", "-q", type = "character", default = "umi",
       help = "count number for each clonotype in each sample, choices can be: cells: the number of cell for each clonotype in each sample; umi: the UMI number for each clonotype in each sample; reads：the reads for each clonotype in each sample. [default: umi]")
sub_vdj$add_argument("--maketse", "-e", type = "character", default = "FALSE",
       help = "whether to construct the TreeSummarizedExperiment object to store data for later diversity analysis.[default: FALSE]")
sub_vdj$add_argument("--bcprefix", "-x", type = "character", default = "sampleid",
       help = "prefix the cell barcode with sample id or row index in metadata.tsv. Options can be sampleid or index.[default: %(default)s]")
sub_vdj$add_argument("--vdjformat", "-v", type = "character", default = "vdjtools",
       help = "the output format of the V(D)J clonotypes table. Options can be vdjtools or immunarch.[default:vdjtools]")


sub_runcicero = subparsers$add_parser("runcicero", help = "run Cicero for predicting gene activity, CCANS and Links.")
sub_runcicero$add_argument("--window","-w", type = "integer", default = 500000,
                            help = "the genome sliding window to determine the distance threshold for calculating coaccess peaks. [default: 500000].")
sub_runcicero$add_argument("--run-ccan", type = "character", default = "FALSE",
                           help = "[OPTIONAL]wether to find cis-Co-accessibility Networks (CCANS).[default: FALSE]")
sub_runcicero$add_argument("--do-norm", type = "character", default = "TRUE",
                           help = "[OPTIONAL]wether to normalize the count matrix from cicero.[default: TRUE]")

sub_monocl3 = subparsers$add_parser("monocle3", help = "run monocle3 on the input data object")
sub_monocl3$add_argument("--reduct", type = "character", default = "umap",
                         help = "the reduction method used for trajectory.")

sub_st_deconv = subparsers$add_parser("st_deconv", help = "deconvolute the compositions of cell types for spatial transcriptomics or bulk transcriptomics data using scRNA-seq data.")
opt = parser$parse_args()
#================== GLOBAL PARAMETERS PARSING ===================================
# setting the output directory
if ( is.null(opt$output) ){
    print("NO output directory specified,the current directory will be used!")
    output_dir = getwd()
}else{
    if ( file.exists(opt$output) ){
        output_dir = opt$output
    }else{
        output_dir = opt$output
        dir.create(output_dir,recursive = T)
    }
}
output_dir = normalizePath(output_dir )

# check the input data object
if ( is.null(opt$dataslot) ){
  dataslots = NULL
}else{
  dataslots = unlist( strsplit(opt$dataslot, ",") )
}

if ( !is.null(opt$subassay) ){
  assays =  union(opt$assay, unlist(strsplit(opt$subassay,",")))
}else{
  assays = opt$assay
}


invisible(gc(full = T, verbose = F))
options(future.globals.maxSize= Inf ) # setting the maxumium mermory usage much bigger in case of big data
future::plan("multicore", workers = min(future::availableCores(), opt$ncores)) # parallization using specified CPUs start from here

# print(dataslots)
# stop("XXXXXA")

#================== SUBCOMMAND INVOKE ==========================================
# ================ Subcmd: create data object from specified source ========
args<-commandArgs(TRUE)

if ( "create" %in% args ){ # create data object from raw data source
  # collect the additional parameters

  data_ob <- switch (tolower(opt$source),
    "mtx" = { # data come from cellranger count results in mtx format
      seux = OESingleCell::CreateX(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   source = opt$source, assay = opt$assay,
                                   aggr = as.logical(opt$aggr),
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   gene.column = opt$gcolumn,
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    "h5" = { # read raw data from cellranger count results in hdf5 format
      seux = OESingleCell::CreateX(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   source = opt$source, assay = opt$assay,
                                   aggr = as.logical(opt$aggr),
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    "xsv" = { # data from text file

    if ( !is.null(opt$metadata) ){
            assay_metadata = read.csv(opt$metadata,sep=",",header =T, colClasses = c("character") )
            rownames(assay_metadata) = assay_metadata$sampleid
        }
        tenx_path = normalizePath(sub("\\/$","",opt$input,perl=T))
        matrix_path = file.path( tenx_path, assay_metadata$sampleid)

        # matrix_path = apply( assay_metadata,1, function(samplex) file.path(tenx_path,samplex["sampletsv"]))
        names(matrix_path) = assay_metadata$sampleid
        # TO DO mkdir
        # tranform the tsv to mtx and then read in the expression matrix using Read10X
        options(future.globals.maxSize= Inf ) # setting the maxumium mermory usage much bigger in case of big data
        plan("multicore", workers = length(matrix_path))
        print("start to create file")
        seu_list <- future.apply::future_lapply(seq_along(matrix_path), function(idx){
          mtx_dir = matrix_path[idx]
          print(mtx_dir)
          names(mtx_dir) = names(matrix_path)[idx]
          barcode_number = read.delim(gzfile(file.path(mtx_dir,"barcodes.tsv.gz")),sep="\t",comment.char = '#',header = F)
          barcode_letter = unlist(lapply(1:dim(barcode_number)[1],function(x) paste(sample(LETTERS[c(1,3,7,20)], size=22, replace=TRUE), collapse = "")))
          term_barcode = cbind(barcode_letter,barcode_number)
		  new_barcode = paste0(term_barcode$barcode_letter,"_",term_barcode$V1)
          write.table( new_barcode, file.path(mtx_dir,"barcodes.tsv"), col.names=F, row.names=F,quote=F)
          input_barcode = file.path(mtx_dir,"barcodes.tsv")
          system(glue::glue("gzip -f {input_barcode} "))

          #names(term_barcode) = c("barcode","bd_idx")
          #write.table( term_barcode, file.path(mtx_dir,"barcodes_pair.txt"), col.names=T, row.names=F,quote=F,sep="\t")
          #term_barcode = tibble::column_to_rownames(term_barcode,var = "barcode")
          countMatrixSparse <- Seurat::Read10X(mtx_dir)
          #seu <- Seurat::CreateSeuratObject( countMatrixSparse, names.field = 2, assay = opt$assay,names.delim = "-" )
		  if ( class(countMatrixSparse) == "list" ){ # there is different library_type in this assay
		     #construct the seurat object using the meta data above
		     if ( !is.null(countMatrixSparse[["Gene Expression"]]) ){
		         seu <- CreateSeuratObject( countMatrixSparse[["Gene Expression"]], names.field = 2, assay = opt$assay, names.delim = "-" )
		     }
		     if ( !is.null(countMatrixSparse[["Antibody Capture"]]) ){
		  	   rownames(countMatrixSparse[["Antibody Capture"]]) <- 
		  					   gsub("_[control_]*pAbO", "", rownames(countMatrixSparse[["Antibody Capture"]]))
		         seu[["ADT"]] <- CreateAssayObject(counts = countMatrixSparse[["Antibody Capture"]][, colnames(seu)])
		     }
		     if ( !is.null(countMatrixSparse[["CRISPR Guide Capture"]]) ){
		  	   rownames(countMatrixSparse[["CRISPR Guide Capture"]]) <- 
		  					   gsub("_[control_]*pAbO", "", rownames(countMatrixSparse[["CRISPR Guide Capture"]]))
		         seu[["CRISPR"]] <- CreateAssayObject(counts = countMatrixSparse[["CRISPR Guide Capture"]][, colnames(seu)])
		     }
		     
		  }else{
		     #construct the seurat object using the meta data above
		     seu <- Seurat::CreateSeuratObject( countMatrixSparse, names.field = 2, assay = opt$assay,names.delim = "-" )
		  }
		  seu
        }
        )
        if (length(seu_list) > 1) {
            seurat_ob <- merge(seu_list[[1]], seu_list[2:length(seu_list)])
        }else {
            seurat_ob <- seu_list[[1]]}
        Seurat::DefaultAssay(seurat_ob)="RNA"
        #assay_metadata = assay_metadata %>% select(-sampletsv)
        #add in the metadata of all cells
        #preserve the sample group infomation into the seurat object,the order of the sample
        #is the same as the order in the metadata list
        cellnames = Seurat::Cells(seurat_ob)
        #the barcodes of cells in first sample don't prefix with sample index number
        #so we add it for convenince
        sampleidx =  gsub("_[ATGC]{16,}.*","",cellnames,perl=T) #the index order is the same as the row index of the assay metadata
        #integrate the metadata from the assay design
        cell_meta = vector( )
        for ( colidx in colnames(assay_metadata) ){
          cell_meta= cbind(cell_meta, as.vector(assay_metadata[sampleidx, colidx]))
        }
        colnames(cell_meta) = colnames(assay_metadata)
        rownames(cell_meta) = cellnames
        cell_meta = as.data.frame(cell_meta)
        cell_meta$orig.ident = cellnames
        #construct the seurat object using the meta data above
        seux <- Seurat::AddMetaData( seurat_ob, metadata = cell_meta )
		seux@meta.data$rawbc = seux@meta.data$orig.ident
    }
  )
  data_ob = seux
  print("done to create file")
  if ( !is.null(opt$gset) ){
    # gmt = GSEABase::getGmt(con=opt$gset)
    gmt_list = unlist(strsplit(opt$gset,",",perl = T))
    #gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gset))
    gset_list <- lapply(gmt_list, function(gmtfile){
                        gset_list <- GSEABase::geneIds(GSEABase::getGmt(con=gmtfile))  
                        return(gset_list)
    })
    genelist = rownames(data_ob@assays$RNA@counts)
    gset_list[[1]]$percent.mito <- intersect(gset_list[[1]]$percent.mito,genelist)
    gset_list[[2]]$percent.HB <- intersect(gset_list[[2]]$percent.HB,genelist)
    for (i in c(1:length(gset_list))){
        data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = NULL, gset = gset_list[[i]])
    }
  } else if (!is.null(opt$metrics)) {
    # metrics = c("percent.mito", "CC.difference"),
    metrics = unlist( strsplit(opt$metrics, ","))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = metrics)
  }
  if ( !is.null(opt$feature.meta) ){
    data_ob = OESingleCell::addFeatureAnno( data_ob,
                                            assay = opt$assay,
                                            gtf = opt$feature.meta)
  }
  data_ob = Seurat::SetIdent(data_ob,value = "sampleid")
  # Now the h5seurat format is used as the standard data object in disk or better interpre
  if ( tolower(opt$outformat) == "h5seurat" ){
    prefix = file.path(output_dir, opt$prefix)
    SeuratDisk::SaveH5Seurat(data_ob, filename = glue::glue("{prefix}.h5seurat") ,
                             overwrite = TRUE, verbose = FALSE)
  }else{
    OESingleCell::SaveX(data_ob, output = output_dir,
                        outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  }
  quit()
}


# ================ Subcmd: multimodal, create data object from multimodal assay ========
if ( "multimodal" %in% args ){ # create data object from raw data source
  # collect the additional parameters
  data_ob <- switch (tolower(opt$source),
    "h5" = { # read raw data from cellranger count results in hdf5 format
      seux = OESingleCell::CreateMultiModal(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   source = opt$source, assay = assays[1],
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    stop("Only hdf5 file SUPPORTED for multimodal assay!")
  )

  if ( !is.null(opt$gset) ){
    # gmt = GSEABase::getGmt(con=opt$gset)
    gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gset))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = NULL, gset = gset_list)
  }
  data_ob = Seurat::SetIdent( data_ob, value = "sampleid")
  # metrics = c("percent.mito", "CC.difference"),
  if ( !is.null(opt$metrics) ){
    metrics = unlist( strsplit(opt$metrics, ","))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = metrics)
  }

  if ( !is.null(opt$feature.meta) ){
      data_ob = OESingleCell::addFeatureAnno( data_ob,
                                              assay = opt$assay,
                                              gtf = opt$feature.meta  )
  }

  # Now the h5seurat format is used as the standard data object in disk or better interpre
  if ( tolower(opt$outformat) == "h5seurat" ){
    prefix = file.path(output_dir, opt$prefix)
    SeuratDisk::SaveH5Seurat(data_ob, filename = glue::glue("{prefix}.h5seurat") ,
                             overwrite = TRUE, verbose = FALSE)
  }else{
    OESingleCell::SaveX(data_ob, output = output_dir,
                      outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  }
  quit()
}

# ======================== Subcmd: one stop of qc workflow ==================================
if ( "qc" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input,
                                informat = opt$informat,
                                reductions = "pca",
                                assays = assays, # only RNA assay is valid
                                data.use = "counts",
                                verbose = F)
  data_ob = Seurat::SetIdent( data_ob, value = "sampleid")
  filter_params = unlist(strsplit(opt$filters, ",", perl =T))
  vars2regress = unlist(strsplit(opt$vars2regress, ",", perl =T))
  data_ob@meta.data$log10GenesPerUMI <- log10(data_ob@meta.data$nFeature_RNA)/log10(data_ob@meta.data$nCount_RNA)
  if ( "CC.Difference" %in% vars2regress ){
      s.genes = Seurat::CaseMatch(search = Seurat::cc.genes$s.genes, match = rownames(data_ob) )
      g2m.genes = Seurat::CaseMatch(search = Seurat::cc.genes$g2m.genes, match = rownames(data_ob) )
      data_ob = Seurat::CellCycleScoring(data_ob, s.features = s.genes, g2m.features = g2m.genes,set.ident = F)
      cycleS = Seurat::FetchData(data_ob, vars = c("S.Score", "G2M.Score") )
      data_ob = OESingleCell::AddMetaData(data_ob, col.name = "CC.Difference",
                           metadata = cycleS[["S.Score"]] - cycleS[["G2M.Score"]])
  }

  # TO DO
  # add support of median calculation
  # 3 valid digits
  # vlnplot before and after QC
  nsamples = length(unique(Seurat::FetchData(data_ob, vars = "sampleid" )[["sampleid"]]))
  if (nsamples <= 4){
    nsamples = nsamples
    ncol = 3
    height = 5
  }else{
    nsamples = nsamples/2
    ncol = 3
    height = 8
  }
  ggvln_before_QC = Seurat::VlnPlot(data_ob, features = filter_params,
                                   group.by = "sampleid", alpha = 0.5,
                                   pt.size = opt$pointsize, ncol = ncol)
  OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_beforeQC"),
                             plot = ggvln_before_QC,
                             height = height,
                             limitsize = F,
                             width = nsamples*length(filter_params) + 3 )
  summx_params = unique(c(filter_params, vars2regress))
  statistics_beforeQC_sim = Seurat::FetchData(data_ob, vars = c("sampleid") ) %>%
    dplyr::group_by(sampleid) %>%
    dplyr::summarise(
            Total_cells_beforeQC = dplyr::n()) %>%
    tibble::column_to_rownames(var = "sampleid")
  statistics_beforeQC =  Seurat::FetchData(data_ob, vars = c( summx_params,"sampleid") ) %>%
    dplyr::group_by(sampleid) %>%
    dplyr::summarise(
            dplyr::across(where(is.numeric),
                          list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
            total_cells = dplyr::n()) %>%
    tibble::column_to_rownames(var = "sampleid")
  before_grid = expand.grid(c("mean", "median"), summx_params, "beforeQC")
  colx_before = c( paste( before_grid[[1]], before_grid[[2]], before_grid[[3]], sep = "_"),
                  "Total_cells_beforeQC")
  colnames(statistics_beforeQC)  = colx_before

  if ( toupper(opt$QC) == "TRUE" ){
      # parse the parameters for metrics' bounds
      lower_threshold = sapply( unlist(strsplit(opt$lower, ",") ),
                                function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
      if ( length(lower_threshold) != length(filter_params) )
          stop("The lower threshold setting is not consistant with the parameters in --filters!")
      names(lower_threshold) = filter_params

      upper_threshold = sapply( unlist(strsplit(opt$upper, ",") ),
                                function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
      if ( length(upper_threshold) != length(filter_params) )
          stop("The upper threshold setting is not consistant with the parameters in --filters!")
      names(upper_threshold) = filter_params
      bounds_list = list()
      for ( x in filter_params)  bounds_list[[x]] = c(min = unname(lower_threshold[x]), max = unname(upper_threshold[x]) )

      ## auto calculate for percent.mito
      if ( "percent.mito" %in% filter_params) {
        if ( (!is.null(bounds_list$percent.mito)) & is.na(bounds_list$percent.mito["max"])) {
            print("Auto calculating percent.mito cut-off…")
            Q90 = ceiling(quantile(data_ob$percent.mito,0.9)/0.05)*0.05
            if (Q90 > 0.2) {
                warning("The 90th percentile of percent.mito exceed 20% !!!"); 
                Q90 = 0.2
            }
            print(paste0("The percent.mito cut-off is set as ",Q90,"."))
            bounds_list$percent.mito["min"] <- 0
            bounds_list$percent.mito["max"] <- Q90
        }
      }
      # Calculate the QC metrics for each cell
      # The number of genes and UMIs are automatically calculated for every object by Seurat.
      # For non-UMI data, nUMI represents the sum of the non-normalized values within a cell.
      # We calculate the percentage of mitochondrial genes here and store it in percent.mito using AddMetaData.
      # AddMetaData adds columns to cell annotation table, and is a great place to stash QC stats
      # ,since this represents non-transformed and non-log-normalized counts.
      # The % of UMI mapping to MT-genes is a common scRNA-seq QC metric.
      #calculate the mitochondrial gene derived transcript proportion and add to the metadata
      # assays = ifelse( !is.null(opt$subassay), opt$assay, c(opt$assay, unlist(strsplit(opt$subassay,","))))
      for ( assayx in assays ){
        if ( assayx %in% c("ADT", "CRISPR") ) next
        # Filter unquanlified cells using different methods
        # We filter out cells that have unique gene counts over 2,500 or less than
        # 200. Note that low.thresholds and high.thresholds are used to define a
        # 'gate'. -Inf and Inf should be used if you don't want a lower or upper
        # threshold.
        # if each filter's lower or upper threshold is specified from the command line
        # the user defined value will be used. Otherwise,the default threshold will
        # be calculated using the distribution significant level specified automatically
        # All the thresholds are specific for each sample, so when the threshold and the
        # standard variance fold are both
        # available from the command line, we will compare the value with the one derived
        # from the distribution lower outliner
        outliers = OESingleCell::FindOutliers(data_ob, vars = filter_params,
                                              var.limit = bounds_list, batch = "sampleid",
                                              type = "both", cut.1 = opt$cut.1, cut.2 = opt$cut.2,
                                              n = opt$nfold, log = FALSE )
        outliercells = do.call(cbind, outliers)
        metric_outlier = apply(outliercells, 1, function(x) any(x == T))
        data_ob = OESingleCell::AddMetaData(data_ob, metadata = metric_outlier,
                                            col.name = "is_metric_outlier")
        outlier_variables = "is_metric_outlier"
        # find outlier cells using roboust linear model between the specified corresponding variable
        # and the dependent variable
        if ( !is.null( opt$rlm.xy) ){
          rlm.xy = unlist(strsplit(opt$rlm.xy, ":"))
          rlmoutlier = OESingleCell::FindRlmOutlier(data_ob, y = rlm.xy[2], x = rlm.xy[1])
          data_ob = OESingleCell::AddMetaData(data_ob, metadata = rlmoutlier,
                                              col.name = "is_rlmoutliers")
          outlier_variables = c( outlier_variables, "is_rlmoutliers")
        }

        is_valid_cell = !apply(OESingleCell::FetchData(data_ob, vars = outlier_variables), 1, function(x) any(x == T))
        data_ob = OESingleCell::AddMetaData(data_ob, metadata = is_valid_cell, col.name = "is_valid")
        #statistics of QC thresholds
        thresholds = do.call(cbind,
                             lapply(names(outliers), function(x) {
                               cut = t(attr(outliers[[x]], "threshold"))
                               colnames(cut) = paste( x, colnames(cut), sep = "_")
                               cut}) )

        value_range  = subset(data_ob@meta.data, subset = is_valid == TRUE ) %>% dplyr::group_by(sampleid) %>% 
                         dplyr::summarise( dplyr::across(names(outliers), 
                         list( min = min,  max = max))) %>% tibble::column_to_rownames(var = "sampleid")

        # statistics of metadat after QC
        ggvln_after_QC = Seurat::VlnPlot(subset(data_ob, subset = is_valid == TRUE ),
                                        features = filter_params, alpha = 0.5,
                                        group.by = "sampleid", pt.size = opt$pointsize, ncol = ncol)
        OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_afterQC"),
                                   plot = ggvln_after_QC,
                                   height = height,
                                   limitsize = F,
                                   width = nsamples*length(filter_params)+3)
        statistics_afterQC_sim = Seurat::FetchData(data_ob, vars = c("sampleid","is_valid") ) %>%
          dplyr::filter(is_valid == TRUE) %>% 
          dplyr::group_by(sampleid) %>%
          dplyr::summarise(
                  Total_cells_afterQC = dplyr::n()) %>%
          tibble::column_to_rownames(var = "sampleid")
        statistics_afterQC = Seurat::FetchData(data_ob, vars = unique(c(filter_params, vars2regress,"sampleid","is_valid")) ) %>%
            dplyr::filter(is_valid == TRUE) %>%
            dplyr::group_by(sampleid) %>%
            dplyr::summarise(
                  dplyr::across(where(is.numeric),
                                list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
                  total_cells = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")
        after_grid = expand.grid(c("mean", "median"), summx_params, "afterQC")
        colx_after = c( paste( after_grid[[1]], after_grid[[2]], after_grid[[3]], sep = "_"),
                        "Total_cells_afterQC")
        colnames(statistics_afterQC)  = colx_after
        #     #merge the statitics by columns
        #cell_statitics = cbind(statistics_beforeQC, statistics_afterQC, thresholds)
        cell_statitics = cbind(statistics_beforeQC, statistics_afterQC, thresholds)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
        cell_statitics = cbind(statistics_beforeQC_sim, statistics_afterQC_sim, value_range)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
      }

      # filter genes by using the minimium cell number one gene is detected
      # this step shoud be run after cell filtering, because there may be
      # satisfied cell number for one gene before filtering
      # but fails after cell filtering
      if ( !is.null(opt$genes2filter) ){
          if ( file.exists( opt$genes2filter) ){
              genes2filter = read.csv(opt$genes2filter,sep=",",header =T )
          }
          genes2filter = as.vector(genes2filter$gene)
      }else{
        genes2filter = NULL
      }

      if ( opt$mincell4gene < 1 ){ #the parameter is a percentage
          min.cell_N = round(opt$mincell4gene * ncol(data_ob))
      }else{ #the parameter is a integer
          min.cell_N = opt$mincell4gene
      }
      data_ob = OESingleCell::FilterGenes(data_ob, min.cells = min.cell_N, filter.genes = genes2filter )

      # now actually filter outlier cells
      data_ob = subset(data_ob, subset = is_valid == TRUE )
  }

  if (toupper(opt$rmdoublets) == "TRUE"){
    RunDoubletFinder <- function(
      object,
      PCs = 1:30,
      doublet.rate = 0.06,
      db.ratio = 0.25,
      nb.size = 0.09,
      sct = FALSE,
      GT = FALSE,
      GT.calls = NULL,
      identity = NULL,
      ...
    ){
      #Set pN-pK param sweep ranges
      pK <- c(0.0005, 0.001, 0.005, seq(0.01,0.3,by=0.01)) # 34
      pN <- seq(0.05,0.3,by=0.05)

      # Remove pK values with too few cells
      min.cells <- round(ncol(object)/(1-0.05) - ncol(object) )
      pK.test <- round(pK*min.cells)
      pK <- pK[which(pK.test >= 1)]

      # Down-sample cells to 10000 (when applicable) for computational effiency
      data <- SeuratObject::GetAssayData(object, slot = "counts")
      if ( ncol(object) > 10000 ) {
        real.cells <- colnames(object)[sample(1:ncol(object), 10000, replace=FALSE)]
        data <- data[ , real.cells]
      }else{
        real.cells <- colnames(object)
      }

      # Iterate through pN, computing pANN vectors at varying pK
      n.real.cells <- length(real.cells)
      output2 <- future.apply::future_lapply(pN, function(x){
        # Make merged real-artifical data
        print(paste("Creating artificial doublets for pN = ", x*100,"%",sep=""))
        n_doublets <- round(n.real.cells/(1 - x) - n.real.cells)
        real.cells1 <- sample(real.cells, n_doublets, replace = TRUE)
        real.cells2 <- sample(real.cells, n_doublets, replace = TRUE)
        doublets <- (data[, real.cells1] + data[, real.cells2])/2
        colnames(doublets) <- paste("X", 1:n_doublets, sep = "")
       data_wdoublets <- cbind(data, doublets)

        ## Pre-process Seurat object
        seu_wdoublets <- SeuratObject::CreateSeuratObject(counts = data_wdoublets)
        if (sct == FALSE){
          seu_wdoublets <- Seurat::NormalizeData(seu_wdoublets)
          seu_wdoublets <- Seurat::FindVariableFeatures(seu_wdoublets)
          seu_wdoublets <- Seurat::ScaleData(seu_wdoublets)
        }else{
          seu_wdoublets <- Seurat::SCTransform(seu_wdoublets)
        }

        seu_wdoublets <- Seurat::RunPCA(seu_wdoublets, verbose=FALSE)
        ## Compute PC distance matrix
        nCells <- ncol(seu_wdoublets)
        pca.coord <- SeuratObject::Embeddings(seu_wdoublets, reduction = "pca")[,PCs]
        # pca.coord <- object_wdoublets@reductions$pca@cell.embeddings[ , PCs]
        rm(seu_wdoublets);gc()
        dist.mat <- fields::rdist(pca.coord)[,1:n.real.cells]

        # Pre-order PC distance matrix prior to iterating across pK for pANN computations
        for (i in 1:n.real.cells) {
          dist.mat[,i] <- order(dist.mat[,i])
        }

        # Trim PC distance matrix for faster manipulations
        ind <- round(nCells * max(pK))+5
        dist.mat <- dist.mat[1:ind, ]

        ## Compute pANN across pK sweep
        print("Computing pANN across all pK...")
        sweep.res.list = list()
        list.ind = 0
        for (k in 1:length(pK)) {
          print(paste("pK = ", pK[k], "...", sep = ""))
          pk.temp <- round(nCells * pK[k])
          pANN <- as.data.frame(matrix(0L, nrow = n.real.cells, ncol = 1))
          colnames(pANN) <- "pANN"
          rownames(pANN) <- real.cells
          list.ind <- list.ind + 1

          for (i in 1:n.real.cells) {
            neighbors <- dist.mat[2:(pk.temp + 1),i]
            pANN$pANN[i] <- length(which(neighbors > n.real.cells))/pk.temp
          }

          sweep.res.list[[list.ind]] <- pANN
        }
        sweep.res.list
     }, future.seed = 2020)

      ## Write parallelized output into list
      sweep.list <- list()
      list.ind <- 0

      for(i in 1:length(output2)){
        for(j in 1:length(output2[[i]])){
          list.ind <- list.ind + 1
          sweep.list[[list.ind]] <- output2[[i]][[j]]
        }
      }

      ## Assign names to list of results
      name.vec <- NULL
      for (j in 1:length(pN)) {
        name.vec <- c(name.vec, paste("pN", pN[j], "pK", pK, sep = "_" ))
      }
      names(sweep.list) <- name.vec

      ## Set pN-pK param sweep ranges
      # require(KernSmooth); require(ROCR)
      # name.vec <- names(sweep.list)
      name.vec <- unlist(strsplit(name.vec, split="pN_"))
      name.vec <- name.vec[seq(2, length(name.vec), by=2)]
      name.vec <- unlist(strsplit(name.vec, split="_pK_"))
      pN <- as.numeric(unique(name.vec[seq(1, length(name.vec), by=2)]))
      pK <- as.numeric(unique(name.vec[seq(2, length(name.vec), by=2)]))
      print(paste("PK ==+ ", pK, "..."))
      print(paste("PN ==+ ", pN, "..."))
      ## Initialize data structure w/ or w/o AUC column, depending on whether ground-truth doublet classifications are available
      if ( GT == TRUE ) {
        sweep.stats <- as.data.frame(matrix(0L, nrow=length(sweep.list), ncol=4))
        colnames(sweep.stats) <- c("pN","pK","AUC","BCreal")
        sweep.stats$pN <- factor(rep(pN, each=length(pK), levels = pN))
        sweep.stats$pK <- factor(rep(pK, length(pN),levels = pK))
      }else{
        sweep.stats <- as.data.frame(matrix(0L, nrow=length(sweep.list), ncol=3))
        colnames(sweep.stats) <- c("pN","pK","BCreal")
        sweep.stats$pN <- factor(rep(pN, each=length(pK), levels = pN))
        sweep.stats$pK <- factor(rep(pK, length(pN),levels = pK))
      }

      ## Perform pN-pK parameter sweep summary
      for (i in 1:length(sweep.list)) {
        res.temp <- sweep.list[[i]]

        ## Use gaussian kernel density estimation of pANN vector to compute bimodality coefficient
        gkde <- approxfun(KernSmooth::bkde(res.temp$pANN, kernel="normal"))
        x <- seq(from=min(res.temp$pANN), to=max(res.temp$pANN), length.out=nrow(res.temp))
       gkdx = gkde(x)
        sweep.stats$BCreal[i] <- bimodality_coefficient(gkdx)

        if (GT == FALSE) { next }

        ## If ground-truth doublet classifications are available, perform ROC analysis on logistic
        ## regression model trained using pANN vector
        meta <- as.data.frame(matrix(0L, nrow=nrow(res.temp), ncol=2))
        meta[,1] <- GT.calls
        meta[,2] <- res.temp$pANN
        train.ind <- sample(1:nrow(meta), round(nrow(meta)/2), replace=FALSE)
        test.ind <- (1:nrow(meta))[-train.ind]
        colnames(meta) <- c("SinDub","pANN")
        meta$SinDub <- factor(meta$SinDub, levels = c("Doublet","Singlet"))
        model.lm <- glm(SinDub ~ pANN, family="binomial"(link='logit'), data=meta, subset=train.ind)
        prob <- predict(model.lm, newdata=meta[test.ind, ], type="response")
        ROCpred <- ROCR::prediction(predictions=prob, labels=meta$SinDub[test.ind])
        perf.auc <- ROCR::performance(ROCpred, measure="auc")
        sweep.stats$AUC[i] <- perf.auc@y.values[[1]]
      }

      ## Implementation for data without ground-truth doublet classifications
      if ( !"AUC" %in% colnames(sweep.stats) ) {
        ## Initialize data structure for results storage
        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=5))
        colnames(bc.mvn) <- c("ParamID","pK","MeanBC","VarBC","BCmetric")
        bc.mvn$pK <- unique(sweep.stats$pK)
        bc.mvn$ParamID <- 1:nrow(bc.mvn)

        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results
        x <- 0
        for (i in unique(bc.mvn$pK)) {
          x <- x + 1
          ind <- which(sweep.stats$pK == i)
          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, "BCreal"])
          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, "BCreal"])^2
          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, "BCreal"])/(sd(sweep.stats[ind, "BCreal"])^2)
        }
      }else{
        # Implementation for data with ground-truth doublet classifications (e.g., MULTI-seq, CellHashing, Demuxlet, etc.)
        # Initialize data structure for results storage
        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=6))
        colnames(bc.mvn) <- c("ParamID","pK","MeanAUC","MeanBC","VarBC","BCmetric")
        bc.mvn$pK <- unique(sweep.stats$pK)
        bc.mvn$ParamID <- 1:nrow(bc.mvn)

        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results
        x <- 0
       for (i in unique(bc.mvn$pK)) {
          x <- x + 1
          ind <- which(sweep.stats$pK == i)
          bc.mvn$MeanAUC[x] <- mean(sweep.stats[ind, "AUC"])
          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, "BCreal"])
          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, "BCreal"])^2
          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, "BCreal"])/(sd(sweep.stats[ind, "BCreal"])^2)
        }
      }

      # choose parameters
      maxBCmetric    <- max(bc.mvn$BCmetric, na.rm = TRUE)
      pK <- as.numeric(as.character(bc.mvn[bc.mvn$BCmetric==maxBCmetric, ]$pK))

      # compute doublet scores
      annotations    <- OESingleCell::colData(object)[[identity]]  ## ex: annotations <- object_kidney@meta.data$ClusteringResults
      # homotypic.prop <- modelHomotypic(annotations)
      anno.freq <- table(annotations)/length(annotations)
      homotypic.prop <- sum(anno.freq^2)
      nExp_poi       <- round(doublet.rate*ncol(object))  ## Assuming 7.5% doublet formation rate - tailor for your dataset
      nExp   <- round(nExp_poi*(1-homotypic.prop))
      # object.scored     <- doubletFinder_v3(object, PCs =PCs, pN = pN, pK = pK, nExp = nExp_poi.adj, reuse.pANN = FALSE, sct = use.SCT)
      print(paste( "pN =", pN, "pK=", pK, "nExp=", nExp))
      ## Generate new list of doublet classificatons from existing pANN vector to save time
      ## Make merged real-artifical data
      real.cells <- colnames(object)
      data <- SeuratObject::GetAssayData(object, slot = "counts")[, real.cells]
      n_real.cells <- length(real.cells)
      n_doublets <- round(n_real.cells/(1 - db.ratio) - n_real.cells)
      print(paste("Creating",n_doublets,"artificial doublets...",sep=" "))
      real.cells1 <- sample(real.cells, n_doublets, replace = TRUE)
      real.cells2 <- sample(real.cells, n_doublets, replace = TRUE)
      doublets <- (data[, real.cells1] + data[, real.cells2])/2
      colnames(doublets) <- paste("X", 1:n_doublets, sep = "")
      data_wdoublets <- cbind(data, doublets)

      ## Pre-process Seurat object
      print("Creating Seurat object...")
      seu_wdoublets <- SeuratObject::CreateSeuratObject(counts = data_wdoublets)
      if (sct == FALSE){
        print("Normalizing Seurat object...")
        seu_wdoublets <- Seurat::NormalizeData(seu_wdoublets)
        print("Finding variable genes...")
        seu_wdoublets <- Seurat::FindVariableFeatures(seu_wdoublets)
        print("Scaling data...")
        seu_wdoublets <- Seurat::ScaleData(seu_wdoublets)
      }else{
        print("Running SCTransform...")
        seu_wdoublets <- Seurat::SCTransform(seu_wdoublets)
      }
      print("Running PCA...")
      seu_wdoublets <- Seurat::RunPCA(seu_wdoublets, verbose=FALSE)
      ## Compute PC distance matrix
      print("Calculating PC distance matrix...")
      nCells <- ncol(seu_wdoublets)
      pca.coord <- SeuratObject::Embeddings(seu_wdoublets, reduction = "pca")[,PCs]
      k <- round(ncol(seu_wdoublets) * nb.size)
      rm(seu_wdoublets);gc()

      ## Compute PC distance matrix
      print("Calculating PC distance matrix...")
      dist.mat <- fields::rdist(pca.coord)

      ## Compute pANN
      print("Computing pANN...")
      pANN <- as.data.frame(matrix(0L, nrow = n_real.cells, ncol = 1))
      rownames(pANN) <- real.cells
      colnames(pANN) <- "pANN"
      for (i in 1:n_real.cells) {
        neighbors <- order(dist.mat[, i])
        neighbors <- neighbors[2:(k + 1)]
        neighbor.names <- rownames(dist.mat)[neighbors]
        pANN$pANN[i] <- length(which(neighbors > n_real.cells))/k
      }

      print("Classifying doublets..")
      classifications <- rep("FALSE",n_real.cells)
      classifications[order(pANN$pANN[1:n_real.cells], decreasing=TRUE)[1:nExp]] <- "TRUE"
      object <- SeuratObject::AddMetaData(object, metadata = pANN[colnames(object), 1], col.name = paste("pANN", db.ratio, nb.size, nExp, sep="_"))
      object <- SeuratObject::AddMetaData(object, metadata = classifications, col.name = "predicted_doublets")
      return(object)
    }

    bimodality_coefficient <- function(x) {
      n <- length(x)
      S <- (1/n)*sum((x-mean(x))^3)/(((1/n)*sum((x-mean(x))^2))^1.5)
      G <- S*(sqrt(n*(n-1)))/(n-2)
      K <- (1/n)*sum((x-mean(x))^4)/(((1/n)*sum((x-mean(x))^2))^2)-3
      K <- ((n - 1)*((n+1)*K-3*(n-1))/((n-2)*(n-3)))+3
      B <- ((G^2)+1)/(K+((3*((n-1)^2))/((n-2)*(n-3))))
      return(B)
    }
    # data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
    is_doublets <- switch(opt$method,
    # data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid"),
      "scrublet" = {
                      data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
          dbl_all <- future.apply::future_lapply(data_list, function(x){
           if ( length(Seurat::Cells(x)) < 750 ){
                dbl_rates = 0.004
            }else if ( length(Seurat::Cells(x)) %in% 750:1499 ) {
                dbl_rates = 0.008
            }else if ( length(Seurat::Cells(x)) %in% 1500:2499 ) {
                dbl_rates = 0.016
            }else if ( length(Seurat::Cells(x)) %in% 2500:3499 ) {
                dbl_rates = 0.023
            }else if ( length(Seurat::Cells(x)) %in% 3500:4499 ) {
                dbl_rates = 0.031
            }else if ( length(Seurat::Cells(x)) %in% 4500:5499 ) {
                dbl_rates = 0.039
            }else if ( length(Seurat::Cells(x)) %in% 5500:6499 ) {
                dbl_rates = 0.046
            }else if ( length(Seurat::Cells(x)) %in% 6500:7499 ) {
                dbl_rates = 0.054
            }else if ( length(Seurat::Cells(x)) %in% 7500:8499 ) {
                dbl_rates = 0.061
            }else if ( length(Seurat::Cells(x)) %in% 8500:9499 ) {
                dbl_rates = 0.069
            }else if ( length(Seurat::Cells(x)) %in% 9500:10499 ) {
                dbl_rates = 0.076
            }else if ( length(Seurat::Cells(x)) >= 10500 ) {
                dbl_rates = 0.1
            }
            x <- OESingleCell::RunScrublet(x, doublet.rate= dbl_rates )
            dbl_res <- OESingleCell::FetchData(x, var = "predicted_doublets")
          }, future.seed = 123)
        },
      "DoubletFinder" = {
        cellmeta = OESingleCell::colData(data_ob)
        if ( ! opt$ident %in% colnames(cellmeta) ) {
          print("NO specfied cell identity column FOUND in cell annotation!")
                      data_ob = Seurat::FindVariableFeatures(data_ob, loess.span = 0.3,
                            clip.max = "auto", mean.function = "FastExpMean",
                            dispersion.function = "FastLogVMR", num.bin = 20,
                            nfeature = "2000", binning.method = "equal_width" )
                      data_ob = Seurat::ScaleData(data_ob, features = rownames(data_ob), verbose = T )
          data_ob = Seurat::RunPCA(data_ob, npcs = 30, features = OESingleCell::VariableFeatures(data_ob), do.print = F, verbose = F)
        }
        dbl_all = list()
                data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
        for ( x in 1:length(data_list) ){
          if ( length(Seurat::Cells(data_list[[x]])) < 750 ){
                dbl_rates = 0.004
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 750:1499 ) {
                dbl_rates = 0.008
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 1500:2499 ) {
                dbl_rates = 0.016
         }else if ( length(Seurat::Cells(data_list[[x]])) %in% 2500:3499 ) {
                dbl_rates = 0.023
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 3500:4499 ) {
                dbl_rates = 0.031
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 4500:5499 ) {
                dbl_rates = 0.039
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 5500:6499 ) {
                dbl_rates = 0.046
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 6500:7499 ) {
                dbl_rates = 0.054
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 7500:8499 ) {
                dbl_rates = 0.061
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 8500:9499 ) {
                dbl_rates = 0.069
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 9500:10499 ) {
                dbl_rates = 0.076
          }else if ( length(Seurat::Cells(data_list[[x]])) >= 10500 ) {
                dbl_rates = 0.1
          }
          data_list[[x]] <- RunDoubletFinder(data_list[[x]], doublet.rate= dbl_rates, identity = opt$ident )
          dbl_all[[x]] <- OESingleCell::FetchData(data_list[[x]], var = "predicted_doublets")
        }
        dbl_all
          # dbl_all <- future.apply::future_lapply(data_list, function(x){
          #   x <- RunDoubletFinder(x, doublet.rate= opt$dbl_rates, identity = opt$ident )
          #   dbl_res <- OESingleCell::FetchData(x, var = "predicted_doublets")
          # }, future.seed = 123)
      }
    )
    data_ob = OESingleCell::AddMetaData(data_ob, metadata = do.call(rbind, is_doublets)[[1]], col.name = "is_doublets")
    # append all other data not loaded before subsetting for h5seurat formated file.
    # if ( opt$informat == "h5seurat" ) data_ob = SeuratDisk::AppendData(opt$input, data_ob)

    # TO DO
    # add support of median calculation
    # 3 valid digits

    # statistics of metadat after QC
    ggvln_after_rmdoublets = Seurat::VlnPlot(subset(data_ob, subset = is_doublets == FALSE ),
                                     features = filter_params, alpha = 0.5,
                                     group.by = "sampleid", pt.size = opt$pointsize, ncol = ncol)
    OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_afterQC"),
                                plot = ggvln_after_rmdoublets,
                                height = height,
                                limitsize = F,
                                width = nsamples*length(filter_params)+3)
    statistics_after_rmdoublets_sim = Seurat::FetchData(data_ob, vars = c("sampleid","is_doublets") ) %>%
          dplyr::filter(is_doublets == FALSE) %>% 
          dplyr::group_by(sampleid) %>%
          dplyr::summarise(
                  Total_cells_after_rmdoublets = dplyr::n()) %>%
          tibble::column_to_rownames(var = "sampleid")
    statistics_after_rmdoublets = Seurat::FetchData(data_ob, vars = unique(c(filter_params, vars2regress,"sampleid","is_doublets")) ) %>%
         dplyr::filter(is_doublets == FALSE) %>%
         dplyr::group_by(sampleid) %>%
         dplyr::summarise(
               dplyr::across(where(is.numeric),
                             list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
               total_cells = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")
    after_grid = expand.grid(c("mean", "median"), summx_params, "after_rmdoublets")
    colx_after = c( paste( after_grid[[1]], after_grid[[2]], after_grid[[3]], sep = "_"),
                     "Total_cells_after_rmdoublets")
    colnames(statistics_after_rmdoublets)  = colx_after
    ##   #merge the statitics by columns
    if ( opt$QC != "TRUE" ) { ## rmdoublet only 
        cell_statitics = cbind(statistics_beforeQC, statistics_after_rmdoublets)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_rmdoublets.xls"),sep="\t",col.names=T,row.names=F)
    } else { ## merge final stats
        cell_statitics = cbind(statistics_beforeQC, statistics_afterQC,statistics_after_rmdoublets, thresholds)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
    }
    if ( opt$QC != "TRUE" ) { ## rmdoublet only 
        cell_statitics = cbind(statistics_beforeQC_sim, statistics_after_rmdoublets_sim)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_rmdoublets.xls"),sep="\t",col.names=T,row.names=F)
    } else { ## merge final stats
        cell_statitics = cbind(statistics_beforeQC_sim, statistics_afterQC_sim,statistics_after_rmdoublets_sim, value_range)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
    }
    data_ob = subset(data_ob, subset = is_doublets == FALSE)
  }

  #Normalize the raw counts
  if ( tolower(opt$normmeth ) == "sctransform" ){
    # Results are saved in a new assay (named SCT by default) with counts being (corrected)
    # counts, data being log1p(counts), scale.data being pearson residuals;
    # sctransform::vst intermediate results are saved in misc slot of new assay.
    # normalize data with SCTransform()
    data_ob = Seurat::SCTransform(data_ob, method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    if ( "CC.Difference" %in% vars2regress ){
      # s.genes = Seurat::CaseMatch(search = cc.genes$s.genes, match = rownames(object) )
      # g2m.genes = Seurat::CaseMatch(search = cc.genes$g2m.genes, match = rownames(object) )
      # data_ob = Seurat::CellCycleScoring(data_ob, s.features = s.genes, g2m.features = g2m.genes,set.ident = F)
    # cycleS = OESingleCell::FetchData(data_ob, vars = c("S.Score", "G2M.Score") )
    # data_ob = OESingleCell::AddMetaData(data_ob, col.name = "CC.Difference",
                             # metadata = cycleS[["S.Score"]] - cycleS[["G2M.Score"]])
    # normalise again but this time including also the cell cycle scores
    data_ob = Seurat::SCTransform(data_ob, assay = "RNA", method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    }
  }else{
      # When you initialise your Seurat object, both counts and data contain
      # your raw transcripts counts (assuming that's your raw data). While the
      # matrix stored in counts generally remains the raw data, the data in the
      # data slot will be normalised when you run NormalizeData().
      data_ob = OESingleCell::NormalizeData(data_ob, normalization.method = opt$normmeth,scale.factor = 10000)
      #wether to regress out the cell cycle effect
      # genes.inuse = rownames(GetAssayData(object, slot="counts"))

      if ( opt$assay != "RNA" ){
          data_ob = Seurat::ScaleData(data_ob, features = rownames(data_ob), verbose = T )
      }else{
          #remove unwanted source of variance
          vars2regress = unique(vars2regress)
          data_ob = Seurat::FindVariableFeatures(data_ob, loess.span = 0.3,
                              clip.max = "auto", mean.function = "FastExpMean",
                              dispersion.function = "FastLogVMR", num.bin = 20,
                              nfeature = opt$nvfeatures, binning.method = "equal_width" )
          # regress out all the specified the varibales
          data_ob <- Seurat::ScaleData(data_ob, features = rownames(data_ob),
                              vars.to.regress = vars2regress, verbose = T ) #takes some time
      }
	  if ( "ADT" %in% names(data_ob@assays) ){
	      data_ob = Seurat::ScaleData(data_ob, features = rownames(data_ob@assays$ADT), verbose = T ,assay = "ADT")}
  }

  OESingleCell::SaveX(data_ob, output = output_dir,
                      outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  quit()
}


# ========= Subcmd: clustering for dimension reduction and clustering ==========
if ( "bclust" %in% args ){
  if ( tolower(opt$reduct2) %in% c("pca","cca","harmony","ica", "mnn") ){ #if the prevous reduction is primary reduction
       print( "the scondary reduction should not be one of pca, cca, ica, mnn or harmony if specified!")
       print("Change to UMAP method as default!")
       opt$reduct2 = "umap"
  }else{
      opt$reduct2 = tolower(opt$reduct2)
  }

 # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")

  #update the metedata in the data_ob@meta.data with new additional sample metadata
  if ( !is.null(opt$metadata) ){
      additional_metadata = read.csv(opt$metadata,sep=",",header =T )
      rownames(additional_metadata) = additional_metadata$sampleid
      data_ob = UpdataCellMeta(data_ob, metadata = additional_metadata, cell.delm = "-")
  }

  if ( is.null(OESingleCell::colData(data_ob)[["clusters"]]) ){
      # data_ob = StashIdent(data_ob, save.name = "clusters")
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
  }else{
      # if it is the first time to run this script on the data object, the
      # clusters here is actually the sample index.
      # After running this script, the cluster id will be overwrite with
      # the actual cell cluster id.
      data_ob = Seurat::SetIdent( data_ob, value = "sampleid")
  }

  #get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  variablefs = Seurat::VariableFeatures(data_ob)
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }

# Determine statistically significant principal components for clustering
if ( opt$reduct1 %in% OESingleCell::Reductions(data_ob) & as.logical(opt$rerun) == F ){#if previous reduction has been calculated ,donot rerun
    if ( opt$reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
        #check the components
        # find the optimal components for secondary reduction
        optimal_pc = tryCatch(
                  expr = Seurat::Command(data_ob, command = glue::glue("FindNeighbors.{opt$assay}.{opt$reduct1}"), value = "dims"),
                  error = function(...){ return(NULL) }
                )
        optimal_pc = length(optimal_pc)
        if ( is.null(optimal_pc) ){ #if previous optimal components not available
            print( "NO previous optimal components is AVAILABLE, the optimal components number be detected automatically.")
            elb = Seurat::ElbowPlot(data_ob, reduction = opt$reduct1)
            optimal_pc = OESingleCell::FindElbow(elb$data)
            # suppressWarnings({ Misc(data_ob, "optimal_pc") = optimal_pc})
        }
    }else{ # reduct1 is not primary reduction and previouly run without primary reduction
            # the exception is mnn, it's better to be specified from command line with relative low value
            optimal_pc = min(opt$components, ncol(OESingleCell::Embeddings(data_ob,reduction = opt$reduct1)))
    }
    scale_data = Seurat::GetAssayData(data_ob, assay = Seurat::DefaultAssay(data_ob), slot = "scale.data")
}else{ # this can be primary reduction or secondary reduction
    print( "NO specified primary reduction found or forced to rerun! \n Reduction begins!")
    message(paste0("Running ", opt$reduct1, " Dimension Reduction"))
    dim_outdir = file.path(output_dir,paste0(opt$reduct1, "_Dimension_Reduction"))
    if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
    }
    scale_data = Seurat::GetAssayData(data_ob, assay = Seurat::DefaultAssay(data_ob), slot = "scale.data")

    var_features <- data_ob@assays[[assays]]@var.features
    meta_features <- data_ob@assays[[assays]]@meta.features 

    data_ob = OESingleCell::RunDimReduc(data_ob, reduct1.use = opt$reduct1 ,
                        reduct2.use = opt$reduct1,
                        feature.use = variablefs,
                        perplexity = opt$perplexity,
                        assay.use = Seurat::DefaultAssay(data_ob),
                        batch.use = opt$batchid, npcs.use = opt$components )

    data_ob@assays[[assays]]@var.features <- var_features
    data_ob@assays[[assays]]@meta.features <- meta_features

    reduct1_coord = OESingleCell::FetchData(data_ob, vars = c("rawbc", paste0( Seurat::Key(data_ob)[opt$reduct1], 1:2))) %>%
                    dplyr::rename( "Barcode" = "rawbc")
    write.table( reduct1_coord, file.path(dim_outdir, paste0(opt$reduct1, "_Dimension_Reduction_coordination.csv")),
                sep = ",", col.names = T, row.names = F, quote = F)

    optimal_pc = opt$components
    if ( opt$reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
        if (is.null(optimal_pc)){
            optimal_pc = OESingleCell::FindElbow(data_ob, reduction = opt$reduct1 )
        }
    }
}

# in case of dimension number out of the actual.
components2use = min( optimal_pc, ncol(OESingleCell::Embeddings(data_ob,reduction = opt$reduct1)))
# after primary reduction, the scale.data will not be used, so as to delete it for saveing memory
# data_ob[[Seurat::DefaultAssay(data_ob)]] = Seurat::SetAssayData(data_ob[[Seurat::DefaultAssay(data_ob)]], slot = "scale.data", new.data=matrix() )
data_ob[[Seurat::DefaultAssay(data_ob)]] = Seurat::SetAssayData(data_ob[[Seurat::DefaultAssay(data_ob)]], slot = "scale.data", new.data=scale_data )
gc()
# print batchid result
cat("sampleid\tbatchid",unique(paste0(data_ob$sampleid,"\t",data_ob$batchid)),sep="\n",file=file.path(output_dir,paste0("sampleid-batchid.xls")))

######### Clustering with the reduction results using different clustering methods
clustering.alg = c("snn" = 1, "louvain" = 2, "slm" = 3, "leidn" = 4)
message(glue::glue("Beginning to group the cells using algorithm {opt$clusteringuse} with top {components2use} {opt$reduct1} components!" ) )
data_ob = Seurat::FindNeighbors( data_ob, reduction = opt$reduct1, dims = 1:components2use,
                            features = variablefs,
                           nn.eps = 0, force.recalc = T, verbose = F)
data_ob = Seurat::FindClusters(object = data_ob, resolution = opt$resolution,
                               algorithm = clustering.alg[opt$clusteringuse], verbose = F)
message("Clustering Finished!")

######### secondary reduction
# secondary reduction used to detect the community in graph if graph-based clustering
# method used.
if ( !is.null( opt$reduct2) ){
    # message(paste0("Beginning ", opt$reduct2, " Dimension Reduction"))
    dim_outdir = file.path(output_dir,paste0(opt$reduct2, "_Dimension_Reduction"))
    if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
    }
    data_ob = OESingleCell::RunDimReduc(data_ob, reduct1.use = opt$reduct1 , reduct2.use = opt$reduct2,
                            feature.use = variablefs,
                            assay.use = Seurat::DefaultAssay(data_ob),
                            batch.use = opt$batchid, npcs.use = components2use)
    reduct2_coord = OESingleCell::FetchData(data_ob,
                        vars = c("rawbc", paste0( Seurat::Key(data_ob)[opt$reduct2], 1:2))) %>%
                        dplyr::rename( "Barcode" = "rawbc")
    write.table( reduct2_coord, file.path(dim_outdir, paste0(opt$reduct2, "_Dimension_Reduction_coordination.csv")),
    sep = ",", col.names = T, row.names = F, quote = F)
}else{
    opt$reduct2 = opt$reduct1
}

######### save the clustering results
cell_id = Seurat::Idents(data_ob)
new_id = as.numeric(as.vector(cell_id)) + 1 # new cluster id start from 1
names(new_id) = names(cell_id)
new_id = as.factor(new_id)
cell_count_by_cluster = table( new_id )
Seurat::Idents(data_ob) = new_id
cluster_result_colname = paste(Seurat::DefaultAssay(data_ob), opt$reduct2,"res", opt$resolution, sep = ".")
#as default the seurat will store the clustering results in the data_object@ident
#to keep the clutering results using the specified resolution to data_object@metadata for reuse
# data_ob <- Seurat::StashIdent(object = data_ob, save.name = cluster_result_colname)
data_ob[[cluster_result_colname]] = Seurat::Idents(data_ob)
# data_ob <- Seurat::StashIdent(object = data_ob, save.name = "clusters")
data_ob[["clusters"]] = Seurat::Idents(data_ob)
reordered_cell_count_by_cluster = table(Seurat::Idents(data_ob))
cell_count_labels = paste(paste(names(reordered_cell_count_by_cluster),reordered_cell_count_by_cluster,sep="-")," cells")
ggdimplot = Seurat::DimPlot(object = data_ob,reduction = opt$reduct2, dims = c(1,2),
             label = T, group.by= cluster_result_colname,   pt.size = pointsize)
custom_cols =  OESingleCell::SelectColors(1:length(unique(Seurat::Idents(data_ob))), palette = opt$palette)

ggdimplot = ggdimplot + ggplot2::labs(title = "") +
            ggplot2::scale_colour_manual( values = custom_cols,
                                 breaks=levels(Seurat::Idents(data_ob)),
                                 labels = cell_count_labels)
ggplot2::ggsave(file.path(dim_outdir,paste0(opt$reduct2, "_groupby_cluster","_resolution", opt$resolution,"_plot.pdf",collapse="")), plot = ggdimplot)
ggplot2::ggsave(file.path(dim_outdir,paste0(opt$reduct2, "_groupby_cluster","_resolution", opt$resolution,"_plot.png",collapse="")),dpi=1000, plot = ggdimplot)
## clustering result csv
clustering_df = OESingleCell::colData(data_ob) %>%
    dplyr::rename( "Barcode" = "rawbc") %>%
    dplyr::select( Barcode, sampleid, clusters, group)
write.table(clustering_df, quote = F,sep =",",row.names = F,
              file.path(output_dir,paste0("clustering_results.csv",collapse = "")))
if ( as.logical(opt$update) ){
  # OESingleCell::SaveX(data_ob, output = opt$input,update = TRUE,
  #                     outformat = opt$outformat, graphs = Seurat::Graphs(data_ob),
  #                     reduction = c(reduct1, reduct2), commands = Seurat::Command(data_ob),
  #                     misc = NULL, tools = NULL )
  # SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                               # reduction = unique(c(opt$reduct1, opt$reduct2)))
  inputdir = dirname(opt$input)
  file.remove(opt$input)
  OESingleCell::SaveX(data_ob, output = inputdir,update = FALSE,
                      outformat = opt$outformat, prefix = 'filtered')
}else{
  OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                      outformat = opt$outformat, prefix = opt$prefix)
}
quit()
}


# ================= Subcmd: Celltyping invoked=========
if ( "celltyping" %in% args ){
  LEVEL = opt$annolevel
  species = opt$species

 # read the specified assay and data slot in data object into memory
 data_ob = OESingleCell::ReadX(
              input = opt$input, informat = opt$informat,
              assays = assays,
              data.use = dataslots, # "counts"
              reductions = opt$reduct, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              images = FALSE, verbose = FALSE)

  # subset test data object
  if ( !is.null(opt$predicate) ){
      df = colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }
  # pointsize
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }

  # Reference datasets are log2 transformed rather than natural log transformed
  # (Seurat).
  test.sce = Seurat::as.SingleCellExperiment(data_ob)
  test.sce = scuttle::logNormCounts(test.sce)

  if ( is.null(opt$builtinref) & is.null(opt$customref) ) stop("NO reference AVAILABE!")

  refd.list = list()
  if (!is.null(opt$customref)) {
    cref = unlist(strsplit(opt$customref, ",") )
    for( refx in cref ){
      refx = normalizePath(refx)
      refid = gsub("\\..[^\\.]*$","",make.names(basename(refx)))
      refd.list[[refid]] = readRDS(refx)
    }
  }

  if ( !is.null(opt$builtinref) ){
    bref = unlist(strsplit(opt$builtinref, ",") )
    for( refx in bref ){
      refd.list[[refx]] = readRDS(system.file(package = "celldex", lib.loc = glue::glue("{orgnism}/{refx}.rds")))
    }
  }

  # prepare the reference data set
  if ( length(refd.list) > 1 ){
    print("using combined result from multiple datasets")
    ref.labels = lapply( refd.list, function(x) factor(x[[LEVEL]]) )
  }else{
    ref.labels = refd.list[[1]][[LEVEL]]
  }

#  if ( length(refd.list) == 1 ){
#    refd.list = refd.list[[1]]
#  }
  refdata = paste0(names(refd.list), collapse = "_")

  # Run prediction now
  if ( length(refd.list) == 1 ){
    pred = SingleR::SingleR(test.sce, ref = refd.list[[1]],
                   labels = ref.labels,
                   BPPARAM = BiocParallel::MulticoreParam(workers = future::nbrOfWorkers()))
  }else{
    pred = SingleR::SingleR(test.sce, ref = refd.list,
                   labels = ref.labels,
                   BPPARAM = BiocParallel::MulticoreParam(workers = future::nbrOfWorkers()))
  }

  raw.metaname = paste0("raw_", LEVEL, "_celltype")
  data_ob = Seurat::AddMetaData(data_ob, metadata = pred[["labels"]], col.name = raw.metaname)
  if ( length(refd.list) > 1 ){
    celltyping_cols = data.frame(labels = pred$labels)
    for ( dx in names(refd.list) ){
      celltyping_cols[[glue::glue("{dx}_labels")]] = pred[["orig.results"]][[dx]][["labels"]]
    }
    data_ob = Seurat::AddMetaData(data_ob, metadata = celltyping_cols)
  }

  #count the cell number for each cell type
  if ( is.null(OESingleCell::colData(data_ob)[["clusters"]]) ){
      # data_ob = StashIdent(data_ob, save.name = "clusters")
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
      warning("No clusters found in the object. use idents instead.")
  }
  celltyping_stat = OESingleCell::FetchData(data_ob, vars = c("clusters", raw.metaname) )%>%
                    dplyr::group_by(clusters,!!rlang::sym(raw.metaname) ) %>%
                    dplyr::summarize(cell_num=dplyr::n()) %>% dplyr::ungroup()
  write.table(celltyping_stat, quote = F,
              file.path(output_dir,
                        paste0(species, "ref_", refdata,"_", LEVEL, "_celltyping_statistics.xls",collapse="")),
              sep = "\t",row.names = F)


  ## heatmap
  print("2.Plot celltyping heatmap")
  meta.data = OESingleCell::FetchData(data_ob, vars = "clusters" ) %>%
              tibble::rownames_to_column(var = "cells")
  if ( ncol(data_ob) > 40000){
    print("Screening of 50,000 cells in proportion...")
    meta.data = meta.data %>% dplyr::group_by(clusters) %>%
                dplyr::sample_frac(40000/dim(data_ob)[2])
    pred=pred[meta.data$cells,]
  }
  if ( is.null(opt$colorschema) ){
    heatmap_color_schema = (grDevices::colorRampPalette(c("#D1147E", "white", "#00A44B")))(100)
  }else{
    colstrings = unlist(strsplit(opt$colorschema,","))
    heatmap_color_schema = (grDevices::colorRampPalette(colstrings))(100)
  }
  ncells = ifelse(  dim(meta.data)[1] > 70000, 70000, dim(meta.data)[1]  )
  plot_width = (1e5 - ncells)/1e4 * ceiling(ncells/30000)
  ## anno
  #annotation_colors <-  list(Clusters=CustomCol(as.numeric(levels(meta.data$clusters))))
  #names(annotation_colors$Clusters) <- as.numeric(levels(meta.data$clusters))
  annotation_colors = list(Clusters=OESingleCell::SelectColors(sort(data_ob[["clusters"]][[1]]), palette = opt$palette))
  annotation_colors
  if ( length(refd.list) == 1 ){
    ggheat = SingleR::plotScoreHeatmap(pred, cells.use = meta.data$cells,
                      clusters = meta.data$clusters,
                      max.labels = opt$topn, show.labels = F,
                      colors = heatmap_color_schema, order.by = "clusters",
                      annotation_colors=annotation_colors)
    width4legendlabs = max(nchar(names(head(sort(table(as.factor(pred$labels)),decreasing = T),opt$topn))))
    OESingleCell::save_ggplots(
      file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping_heatmap",collapse=".")),
      plot = ggheat, limitsize = F,width = plot_width + width4legendlabs/15 )
  }else{
    refid = c("combine", names(refd.list))
    for ( inx in 0:length(refd.list) ){
      ggheat = SingleR::plotScoreHeatmap(pred,
                                         scores.use = inx,
                                         cells.use = meta.data$cells,
                                         clusters = meta.data$clusters,
                                         max.labels = opt$topn,
                                         show.labels = F,
                                         colors = heatmap_color_schema,
                                         order.by = "clusters")
      width4legendlabs = max(nchar(names(head(sort(table(as.factor(pred$labels)),decreasing = T),opt$topn))))
      OESingleCell::save_ggplots(
        file.path(output_dir,paste0(species,"ref_", refid[inx+1], "_",LEVEL,"_celltyping_heatmap",collapse=".")),
        plot = ggheat, width = plot_width + width4legendlabs/15, )
    }
  }
  ## plot raw celltype
  print("3.Plot celltyping embeddings")
  print(length(unique(data_ob[[raw.metaname]][[1]])))
  
  nlevel = length(unique(data_ob[[raw.metaname]][[1]]))
  ncols = ifelse( nlevel > 30, as.integer(nlevel/30)+1, 1)
  if(length(unique(data_ob[[raw.metaname]][[1]])) >50){
      #custom_cols =  OESingleCell::SelectColors(data_ob[[raw.metaname]][[1]], palette = opt$palette)
      ggdim = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = raw.metaname ) +
                  ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5),
                                  legend.key.size = grid::unit(0.9,"lines"),
                                  legend.text = ggplot2::element_text(size = 10)) +
                  #ggplot2::scale_colour_manual( values = custom_cols ) +
                  ggplot2::guides(colour = guide_legend(ncol = ncols, override.aes = list(size=2)))
      OESingleCell::save_ggplots(filename = file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping", "_plot")),
                                 plot = ggdim, width = (8+ (width4legendlabs/13)* ncols), dpi = 1000,)
  }else {
      custom_cols =  OESingleCell::SelectColors(data_ob[[raw.metaname]][[1]], palette = opt$palette)
      ggdim = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = raw.metaname ) +
                  ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5),
                                  legend.key.size = grid::unit(0.9,"lines"),
                                  legend.text = ggplot2::element_text(size = 10)) +
                  ggplot2::scale_colour_manual( values = custom_cols ) +
                  ggplot2::guides(colour = guide_legend(ncol = ncols, override.aes = list(size=2)))
      OESingleCell::save_ggplots(filename = file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping", "_plot")),
                                 plot = ggdim, width = (8+ (width4legendlabs/13)* ncols), dpi = 1000,)
  }
  ## TOPN result
  # data_ob = Seurat::SetIdent( data_ob, value = "clusters")
  #top_celltype = celltyping_stat %>% dplyr::group_by(clusters) %>% dplyr::top_n(1,cell_num) %>% dplyr::ungroup() 
  top_celltype = celltyping_stat %>% dplyr::group_by(clusters) %>% dplyr::arrange(desc(cell_num)) %>% dplyr::do(head(.,1)) %>% dplyr::ungroup()
  data_ob[[paste0(refdata,".",LEVEL,".celltype")]] = plyr::mapvalues(x = data_ob[["clusters"]][[1]],
                                           from = as.vector(top_celltype[["clusters"]]),
                                           to = as.vector(top_celltype[[raw.metaname]]))
  data_ob[["celltype"]] <- data_ob[[paste0(refdata,".",LEVEL,".celltype")]] # the final celltyping results column

  full_celltyping_df = OESingleCell::colData(data_ob) %>%
    tibble::rownames_to_column(var = "barcode_inuse") %>%
    dplyr::rename( "Barcode" = "rawbc" ) %>%
    dplyr::select( Barcode, everything())
  write.table(full_celltyping_df, quote = F,
              file.path(output_dir,paste0(species,"ref_",refdata,
                                          "_",LEVEL,"_celltyping_results.xls",collapse = "")), sep = "\t", row.names = F)
  simplified_celltyping_df = OESingleCell::colData(data_ob) %>%
    dplyr::rename( "Barcode" = "rawbc") %>%
    dplyr::select( Barcode, sampleid, celltype, clusters,group)
  write.table(simplified_celltyping_df, quote = F,sep =",",row.names = F,
              file.path(output_dir,paste0(species,"ref_",refdata,
                                          "_",LEVEL,"_simplified_celltyping_results.csv",collapse = "")))

  ## obtain the top cluster number for each celltype (for the purpose of coloring)
  # top_celltype[["colors"]] = OESingleCell::SelectColors(top_celltype[["clusters"]], palette = opt$palette)
  colorx = top_celltype %>%
              dplyr::mutate(colors = OESingleCell::SelectColors(clusters, palette = opt$palette)) %>%
              dplyr::select(-c(clusters, cell_num)) %>%
              dplyr::group_by(.data[[raw.metaname]]) %>%
              dplyr::slice_head(n = 1) %>%
              dplyr::ungroup() %>% tibble::deframe()
  ggdim2 = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = "celltype" ) +
            theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
            scale_colour_manual( values = colorx )
  OESingleCell::save_ggplots(file.path(output_dir,paste0(species,"ref_",refdata,"_top.",LEVEL,"_celltyping_plot")),
                               plot = ggdim2, width = (7+ (width4legendlabs/12)* ncols), dpi = 1000,)

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}


# ====================== Subcmd: visualize the markers in different ways =========
if ( "visualize" %in% args ){
  groupby = opt$groupby
  splitby = opt$splitby
  if ( identical(groupby,splitby)){
      warning( "The variable specified by --splitby conflicted with the --groupby parameter, NULL will be used!")
      splitby = NULL
  }

  #determine the color schema for discrete and continious variables
  vcolors = unlist(strsplit(opt$vcolors,","))
  if ( length(vcolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
    if ( is.null(OESingleCell::discrete_palette[[vcolors]]) ){
      info = glue::glue("the customized discrete colors are: \n {paste(names(OESingleCell::discrete_palette), lengths(OESingleCell::discrete_palette), sep =': ', collapse = '\n')}.")
      warning("NO specified color schema found!")
      warning(info)
      stop()
    }
    discrete_colors = OESingleCell::SelectColors(palette = vcolors)
  }else{ # this means to use the customized color schema from command line specified by user
    discrete_colors = vcolors
  }
  ccolors = unlist(strsplit(opt$ccolors,","))
  if ( length(ccolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
    if ( is.null(OESingleCell::continuous_palette[[ccolors]]) ){
      info = glue::glue("the customized continious colors are: \n {paste(names(OESingleCell::continuous_palette), lengths(OESingleCell::continuous_palette), sep =': ', collapse = '\n')}.")
      warning("NO specified color schema found!")
      warning(info)
      stop()
    }
    continious_colors = OESingleCell::SelectColors(palette = ccolors, is.discrete = FALSE)
  }else{ # this means to use the customized color schema from command line specified by user
    continious_colors = ccolors
  }

 # read the specified assay and data slot in data object into memory
 # for visualization usually only "data" slot is loaded,which can save a lot of time and memory
 data_ob = OESingleCell::ReadX(
              input = opt$input, informat = opt$informat,
              assays = assays,
              data.use = dataslots, # "data"
              reductions = opt$reduct, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              verbose = FALSE)
  #get the subset of cells used  if necessay
  if ( !is.null(opt$predicate) ){
    desired_cells= subset(OESingleCell::colData(data_ob), eval( parse(text=opt$predicate)))
    # same for Seurat, SingleCellExperiment, summarizedExperiment
    data_ob = data_ob[,rownames(desired_cells)]
  }

  # if ( is.null(opt$cluster_name) ){
  #   data_ob[["clusters"]] = Seurat::Idents(data_ob)
  # }else{
  #   # data_ob = Seurat::SetIdent( data_ob, value = opt$cluster_name)
  #   data_ob[[opt$cluster_name]] = Seurat::Idents(data_ob)
  # }
  clusters = OESingleCell::FetchData(data_ob, vars = "clusters")[[1]]
  data_ob[["clusters"]] = factor(clusters, levels = sort( unique(as.numeric(clusters))))

  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }
  if ( is.null( opt$markers ) & is.null(opt$extraGene)){
      stop("NO marker genes is AVAILABLE!")
  }

  topn_markers = data.frame()
  if ( !is.null(opt$markers) ){
      markers2vis = read.table( opt$markers, sep="\t", header = T )
      topn_markers  = markers2vis %>%
          dplyr::group_by(cluster) %>%
          # dplyr::arrange(p_val, desc(avg_log2FC)) %>%
          dplyr::arrange(desc(gene_diff)) %>%
          dplyr::top_n(opt$topn, wt = !!rlang::sym(opt$topby) ) %>%
          dplyr::arrange(cluster) %>%
          dplyr::mutate(folder_suffix = paste0("cluster",cluster)) %>%
          dplyr::select(cluster,gene,folder_suffix)
  }
  if ( !is.null(opt$extraGene) ){
    extra_gene = read.table(opt$extraGene, sep="\t", header = T)
    if (dim(extra_gene)[2] == 1 && colnames(extra_gene)[1] == "gene"){colnames(extra_gene)[1]="extra"}
    formated_extra_gene = as.data.frame(tidyr::gather(extra_gene,key = "cluster",value = "GENE"))
    match = OESingleCell::CaseMatch(search = as.vector(formated_extra_gene$GENE),match = rownames(data_ob))
    filtered_gene = formated_extra_gene$GENE[!formated_extra_gene$GENE %in% names(match )& formated_extra_gene$GENE != ""]
    if(length(filtered_gene)!=0){
        filtered_gene = as.data.frame(filtered_gene)
        colnames(filtered_gene) = "Gene"
        write.table(filtered_gene,file.path(output_dir,"genes_not_matched.xls"),quote = F,row.names=F)
        print("There are some mismatched gene symbol, Please check genes_not_matched.xls for the genename.")
    }
    formated_extra_gene = formated_extra_gene %>%
                          dplyr::filter(GENE %in% names(match)) %>%
                          dplyr::mutate(gene = match,folder_suffix = cluster) %>%
                          dplyr::select(cluster, gene,folder_suffix)
    topn_markers = rbind(topn_markers, formated_extra_gene)
  }

if ( is.null(opt$vismethod) ){
    print("NO marker gene visulization method provided,the default method vlnplot and featureplot will be used!")
    vismethods = c("vlnplot","featureplot")
}else if( opt$vismethod == "all" ){
    vismethods = c("vlnplot","featureplot","ridgeplot","dotplot","boxplot")
}else{
    vismethods = unlist(strsplit(opt$vismethod,","))
}

cellmeta = OESingleCell::colData(data_ob)
root_dir = output_dir
comp = list()
if ( !is.null(opt$pvalue) ){
  all_comparisions = list()
  contrasts_list = unlist(strsplit(opt$pvalue, "\\+", perl = T))
  # contrasts_list = unlist(strsplit(pvalue, "\\+", perl = T)) ##delete
  for ( contrast in contrasts_list ){
    contrast = paste0(groupby,":",contrast)
    contrasts = unlist( strsplit(contrast,":",perl = T) )
    assay_metadata=data_ob@meta.data
    all_levels = as.vector(unique(assay_metadata[,contrasts[1]]))
    if ( contrasts[2] == "all" & contrasts[3] != "all" ){
        all_levels = all_levels[-which(all_levels==contrasts[3])] #delete the reference level
        all_comparisions = paste(all_levels,contrasts[3],sep = ":")
        break
    }else if( contrasts[2] == "all" & contrasts[3] == "all" ){
        all_comparisions = "all"
        break
    }else if ( contrasts[2] != "all" & contrasts[3] == "all" ){
        all_levels = all_levels[-which(all_levels==contrasts[2])]
        all_comparisions = paste(contrasts[2],all_levels,sep = ":")
        break
    }else{
        if ( !contrasts[2] %in% all_levels | !contrasts[3] %in% all_levels){
          print(paste0(contrasts[2],":",contrasts[3],"所选分组中细胞数为0,请检查分组比较信息。已跳过该分组。"))
        }else if ( table(assay_metadata[,groupby])[contrasts[2]]<=1 | table(assay_metadata[,groupby])[contrasts[3]]<=1){
          print(paste0(contrasts[2],":",contrasts[3],"所选分组中细胞数小于2,请检查分组比较信息。已跳过该分组。"))
        }else{
          all_comparisions = c(all_comparisions , paste0(contrasts[2],":",contrasts[3]))
        }
    }
  }
  my_comparisons = sort(unique((data_ob@meta.data[,groupby]))) ##找到分组信息
  comp=list()
  ##若为all:all,则通过循环生成各个分组两两结合比对的list
  if ( all_comparisions == "all" ){
    for(a in 1:(length(my_comparisons)-1)){
      for(b in 1:(length(my_comparisons)-a)){
      list=c(as.character(my_comparisons[a]),as.character(my_comparisons[a+b]))
      comp=c(comp,list(list))
      }
    }
  }else{
    for( i in all_comparisions ){
      list=strsplit(i,":",perl = T)
      comp=c(comp,list)
    }
  }
}
print(comp)
for ( vismethod in vismethods ){
  if ( vismethod == "vlnplot" ){
    modify_vlnplot<- function(data_ob, gene, pt.size = 0.1, groupby = groupby, plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"), ...) {
      p<- Seurat::VlnPlot(data_ob, 
                features = gene, 
                pt.size = pt.size, 
                group.by = groupby, 
                cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                alpha = 0,... )  + 
      xlab("") + ylab("") + ggtitle(gene) + 
      theme(legend.position = "none", 
          axis.text.x = element_blank(), # 去除x轴文本
          axis.ticks.x = element_blank(), # 去除x轴下方凸出线条
          plot.margin = plot.margin ) 
      return(p)
    }

    StackedVlnPlot<- function(data_ob, gene, pt.size = 0.1, groupby = groupby, plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"), ...) {
      plot_list<- purrr::map(gene, function(x) modify_vlnplot(data_ob = data_ob,gene = x, pt.size = 0.1, groupby = groupby,...))
      plot_list[[length(plot_list)]]<- plot_list[[length(plot_list)]] +
      theme(axis.text.x = element_text(angle = 30))

      p<- patchwork::wrap_plots(plotlist = plot_list, ncol = 1)
      return(p)
    }

    # Draws a violin plot of single cell data (gene expression, metrics, PC scores, etc.)
    for ( clusterx in unique(topn_markers$folder_suffix) ){
      topn = topn_markers %>%
        dplyr::filter( folder_suffix == clusterx) %>%
        dplyr::select(cluster,gene,folder_suffix)
      topn_markers2vis = as.vector(topn$gene)
      topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/10))

      path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
      if ( file.exists( path4vis ) ){
          output_dir = path4vis
      }else{
          output_dir = path4vis
          dir.create(output_dir, recursive = T)
      }
      
      if ( !is.null(opt$pvalue) & length(comp) != 0 ){
        suppressPackageStartupMessages( library("ggsignif") )
        suppressPackageStartupMessages( library("tibble") )
        .libPaths("/home/liuhongyan/miniconda3/envs/scvdj/lib/R/library")
        # .libPaths("/home/liuhongyan/miniconda3/envs/scvdj/lib/R/library")
        suppressPackageStartupMessages( library("ggstatsplot") )
        # suppressPackageStartupMessages( library("dplyr") )
        metadata <- data_ob@meta.data
        for(gene in topn_markers2vis){
          # max.feature.value <- max(data_ob@assays$RNA@data[gene,])
          # max.feature.value=max.feature.value + 0.4*length(comp)+0.5
          value <- as.matrix(data_ob[[assays]]@data[gene, ])
          metadata = data_ob@meta.data %>% tibble::rownames_to_column(var = "id")
          plotdata = cbind(metadata, value )
          plotdata["x"]=plotdata[groupby]
          gs <- ggstatsplot::ggbetweenstats(
            data = plotdata ,
            x = x,
            y = value,
            plot.type = "boxviolin",
            results.subtitle =FALSE,
            messages = FALSE,
            pairwise.comparisons = FALSE, 
            mean.label.size = 0, # size of the label for mean
            centrality.plotting = F,
            ylab = gene
          ) + 
          scale_color_manual(values = discrete_colors[1:length(unique(cellmeta[[groupby]]))])  +
          theme(axis.text.x = element_text(size=8,colour="black"),
               axis.text.y = element_text(size=8,colour="black"),
               panel.grid.major =element_blank(), 
               panel.grid.minor = element_blank(),
               panel.background = element_blank(),
               axis.line = element_line(colour = "black")) +
          geom_signif(comparisons = comp, #指定比较对象
               test = "wilcox.test", #指定检验方法
               size = 0.4, #指定标记中线条的尺寸
               textsize = 2.6, #指定标记中文字部分的大小
               vjust = 3, #指定标记中文字部分与横线之间的距离指定标记中文字部分与横线之间的距离
               step_increase = 0.1, #指定每根线条距离高低
               #tip_length = c(0.2, 0.2), #指定短竖线的长度
               map_signif_level =T )  #F显示具体数值，T显示显著性 
          OESingleCell::save_ggplots(file.path(output_dir, paste0(gene,"_violin_plot_with_pvalue")),
                            plot = gs,width = 7,height = 5+0.3*length(comp),dpi = 1000 ,limitsize = F)
        }
      } else {
      #识别字符串长度
      if(any(nchar(as.character(unique(cellmeta[[groupby]]))) >20)){char_length_excess = TRUE}else{char_length_excess = FALSE}
      if (char_length_excess == TRUE) {
          fig_i = 1
          topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/5))
      for (gene in topn_markers2vis_list) {
          gs = Seurat::VlnPlot(data_ob, features = gene,
                    cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                    pt.size = 0.1, alpha = opt$alpha2use,
                    group.by = groupby,
                    split.by = splitby,
                    split.plot = as.logical(FALSE) ,ncol=1) &
               ggplot2::labs(y = "", x=NULL) &
               ggplot2::theme(
                    legend.position="none",
                    legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                    plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                    axis.text = ggplot2::element_text(margin = ggplot2::unit(0,"null")),
                    axis.title.x = ggplot2::element_text(size = 0),
                    axis.title.y = ggplot2::element_text(size = 12),
                    axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                    axis.text.y=ggplot2::element_text(size = 8))
          if ( length(topn_markers2vis) <= 5 ) {
                    OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                          plot = gs,
                          width = 8 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = length(gene)*3,dpi = 1000 ,limitsize = F)
               } else {
                    OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                          plot = gs,
                          width = 8 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = length(gene)*3,dpi = 1000 ,limitsize = F) 
               }
          fig_i = fig_i + 1
        }
      }else{
        if ( opt$xlab == "TRUE") {
          fig_i = 1
          for (gene in topn_markers2vis_list) {
              gs = Seurat::VlnPlot(data_ob, features = gene,
                        cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                        pt.size = 0.1, alpha = opt$alpha2use,
                        group.by = groupby,
                        split.by = splitby,
                        split.plot = as.logical(FALSE) ,ncol=1) &
                  ggplot2::labs(y = "", x=NULL) &
                  ggplot2::theme(
                        legend.position="none",
                        legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                        plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                        axis.text = ggplot2::element_text(margin = ggplot2::unit(0,"null")),
                        axis.title.x = ggplot2::element_text(size = 0),
                        axis.title.y = ggplot2::element_text(size = 12),
                        axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                        axis.text.y=ggplot2::element_text(size = 8))
              if ( length(topn_markers2vis) <= 10 ) {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 1000 ,limitsize = F)
                  } else {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 1000 ,limitsize = F) 
                  }
              fig_i = fig_i + 1
            }
        }else{
          fig_i = 1
          for (gene in topn_markers2vis_list) {
              gs = StackedVlnPlot(data_ob,gene,pt.size = 0.1,groupby)
              if ( length(topn_markers2vis) <= 10 ) {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 1000 ,limitsize = F)
                  } else {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 1000 ,limitsize = F) 
                  }
              fig_i = fig_i + 1
          }
        }
      }
      }
    }
  }  

  if ( vismethod == "featureplot" ){
      for ( clusterx in unique(topn_markers$folder_suffix) ){
          if ( !opt$reduct %in% Seurat::Reductions(data_ob) ){
              stop( "NO specified reduction found in the object!")
          }else{
              reduct = opt$reduct
          }
          topn = topn_markers %>%
                  dplyr::filter( folder_suffix == clusterx) %>%
                  dplyr::select(cluster,gene,folder_suffix)
          topn_markers2vis = as.vector(topn$gene)
          topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/10))
          path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
          if ( file.exists( path4vis ) ){
              output_dir = path4vis
          }else{
              output_dir = path4vis
              dir.create(output_dir, recursive = T)
          }
          fig_i = 1
          for (gene in topn_markers2vis_list){
              suppressMessages({
               ggfeatures = Seurat::FeaturePlot(data_ob,reduction= reduct,
                                    features = gene, split.by = splitby,
                                    keep.scale = "all",
                                    max.cutoff = 'q99',
                                    order = T,
                                    pt.size = pointsize, 
                                    ncol = ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =2 ) ) &
                          ggplot2::scale_colour_gradientn(colours = colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))(100) ) &
                          # ggplot2::scale_color_gradientn(colours = continious_colors) &
                          ggplot2::theme(legend.position = "none",
                                legend.margin = ggplot2::margin(0,0.5,0,0, unit = "cm"),
                                plot.margin = ggplot2::margin(0.1, 0.1, 0.1, 0.1, unit = "cm"),
                                plot.title = ggplot2::element_text(hjust = 0.5) )
          })
          ggm = ggpubr::ggarrange(ggfeatures,common.legend = T, legend = "right")

          if ( length(topn_markers2vis) <= 10 ) {
               OESingleCell::save_ggplots(
                    file.path(output_dir, paste0("marker_gene_featureplot",collapse="")),
                    width =  4*ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =length(unique(cellmeta[[splitby]]))),
                    height = 4*ifelse(is.null(splitby),
                                yes = ceiling(length(gene)/2),
                                no  = length(gene)),
                    plot = ggm, dpi = 1000 ,limitsize = F,bg="white" )
               } else {
               OESingleCell::save_ggplots(
                    file.path(output_dir, paste0("marker_gene_featureplot_",fig_i,collapse="")),
                    width =  4*ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =length(unique(cellmeta[[splitby]]))),
                    height = 4*ifelse(is.null(splitby),
                                yes = ceiling(length(gene)/2),
                                no  = length(gene)),
                    plot = ggm, dpi = 1000 ,limitsize = F,bg="white" )
               }
          fig_i = fig_i + 1
        }
      }
  }

  if ( vismethod == "boxplot" ){
    # Draws a violin plot of single cell data (gene expression, metrics, PC scores, etc.)
    for ( clusterx in unique(topn_markers$folder_suffix) ){
      topn = topn_markers %>%
        dplyr::filter( folder_suffix == clusterx) %>%
        dplyr::select(cluster,gene,folder_suffix)
      topn_markers2vis = as.vector(topn$gene)

      path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
      if ( file.exists( path4vis ) ){
          output_dir = path4vis
      }else{
          output_dir = path4vis
          dir.create(output_dir, recursive = T)
      }
      # my_comparisons = sort(unique((data_ob@meta.data[,groupby])))
      # comp=list()
      # for(a in 1:(length(my_comparisons)-1)){
      #   for(b in 1:(length(my_comparisons)-a)){
      #   list=c(as.character(my_comparisons[a]),as.character(my_comparisons[a+b]))
      #   comp=c(comp,list(list))
      #   }
      # }
      for (gene in topn_markers2vis) {
          value <- data_ob@assays$RNA@data[gene, ]
          value_data <- as.data.frame(value)
          data_ob@meta.data[, gene] = value_data$value
          # for (i in value_data$value) {
          #     subset_ob <- subset(value_data, value == i)
          #     data_ob@meta.data[rownames(subset_ob), gene] <- i
          # }
      }
      metadata <- data_ob@meta.data
      metadata <- metadata[, c(groupby, topn_markers2vis)]
      for(geneset in topn_markers2vis){
        gene=metadata[,geneset]
        if ( !is.null(opt$pvalue) & length(comp) != 0 ){
        suppressPackageStartupMessages( library("ggsignif") )
        box <- ggplot(metadata, aes_string(x = groupby, y = gene, fill = groupby)) +
        geom_boxplot() +
        labs(x = groupby, y = geneset) +
        ggsignif::geom_signif(comparisons = comp ,test = "wilcox.test" ,map_signif_level = T ,step_increase = 0.1) +
        scale_fill_manual(values = discrete_colors[1:length(unique(cellmeta[[groupby]]))]) +
        theme(
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.position = "none",
            axis.line = element_line(color = "black"))

        OESingleCell::save_ggplots(file.path(output_dir,paste0(geneset,"_boxplot_with_pvalue")),
                          plot = box,
                          width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = 5,dpi = 1000 ,limitsize = F)
        }else{
        box <- ggplot(metadata, aes_string(x = groupby, y = gene, fill = groupby)) +
        geom_boxplot() +
        labs(x = groupby, y = geneset) +
        scale_fill_manual(values = discrete_colors[1:length(unique(cellmeta[[groupby]]))]) +
        theme(
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.position = "none",
            axis.line = element_line(color = "black"))

        OESingleCell::save_ggplots(file.path(output_dir,paste0(geneset,"_boxplot")),
                          plot = box,
                          width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = 5,dpi = 1000 ,limitsize = F)

        }
      }
    }
  }

  if ( vismethod == "dotplot" ){
    # data_ob = Seurat::SetIdent( data_ob, value = groupby )
    Seurat::Idents(data_ob) = groupby
    markers2vis4dotplot = unique(as.vector(topn_markers$gene))
    ggdots = Seurat::DotPlot(object = data_ob,
                             cols = continious_colors,
                             features = markers2vis4dotplot ) + Seurat::RotatedAxis() +
                             ggplot2::scale_colour_gradientn(colours = colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))(100) )
    OESingleCell::save_ggplots(
      file.path(root_dir,"marker_gene_dotplot"),
      plot = ggdots, dpi = 1000 ,limitsize = F , 
      width=(0.3*length(markers2vis4dotplot)+2.5+max(nchar(names(table(data_ob@meta.data[,groupby]))))/10),
      bg="white")
  }

  if ( vismethod == "ridgeplot"){
      for ( clusterx in unique(topn_markers$folder_suffix) ){
        topn = topn_markers %>% filter( folder_suffix == clusterx) %>% dplyr::select(cluster,gene,folder_suffix)
        topn_markers2vis = as.vector(topn$gene)

        path4vis = file.path(output_dir,paste0("markers_vis4",clusterx,collapse = ""))
        if ( file.exists( path4vis ) ){
            output_dir = path4vis
        }else{
            output_dir = path4vis
            dir.create(output_dir, recursive = T)
        }
        # data_ob = Seurat::SetIdent( data_ob, value = groupby )
        Seurat::Idents(data_ob) = groupby
        ggridge = Seurat::RidgePlot(object = data_ob,
                                    features = topn_markers2vis,
                                    cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                                    ncol = 1)
        OESingleCell::save_ggplots(
          file.path(output_dir,"marker_gene_ridgeplot"),
          plot = ggridge, dpi = 1000 ,limitsize = F)
      }
    }
  }

  quit()
}

# ============== Subcmd: findallmarkers Find All markers for each cell group ===============
if ( "findallmarkers" %in% args ){
  #parse the command line parameters
  pct1_cutoff = opt$min_pct1
  pct2_cutoff = opt$max_pct2
  pct_fold_cutoff = opt$pct_fold
  dftest = opt$test
  topn = opt$topn_marker

 # read the specified assay and data slot in data object into memory
 data_ob = OESingleCell::ReadX(input = opt$input,
              informat = opt$informat,
              assays = assays, data.use = dataslots, # "data"
              reductions = FALSE, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              verbose = FALSE)

  #get the subset of cells used  if necessay
  if ( !is.null(opt$predicate) ){
    desired_cells= subset(OESingleCell::colData(data_ob), eval( parse(text=opt$predicate)))
    # same for Seurat, SingleCellExperiment, summarizedExperiment
    data_ob = data_ob[,rownames(desired_cells)]
  }


  #in default, the FindAllMarkers() function will use the default identity class
  #In order to select the different clustering result to find markers, change this
  #class value to one of the column in the cell annotation metadata table
  suppressWarnings({
    if ( is.null(opt$cluster_name) ){
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
    }else{
      # data_ob = Seurat::SetIdent( data_ob, value = opt$cluster_name)
      Seurat::Idents(data_ob) = opt$cluster_name
    }
  })
  #find the differential expressed genes for each clusters
  #FindAllMarkers() is primarily used to find markers, but here it was also used
  #to find differentially expressed genes. The default logfc threshold was set to 0.25
  #,here we set to 0 as no prefiltering and then manually filter the genes to find markers
  # note that if test.use is "negbinom", "poisson", or "DESeq2", slot will be set to "counts" automatically
  global_DEGs = Seurat::FindAllMarkers(object = data_ob,
                                       only.pos = T, test.use = dftest,
                                       logfc.threshold = 0, min.pct = 0.25)
  if ("auc" %in% names(global_DEGs) ) global_DEGs = global_DEGs %>% dplyr::select(-auc)
  global_DEGs = global_DEGs %>%
    dplyr::mutate( gene_diff = round(global_DEGs$pct.1 / global_DEGs$pct.2, 3)) %>%
    dplyr::select( gene, everything() )
  write.table(global_DEGs,file = file.path(output_dir,"all_markers_for_each_cluster.xls"),
            col.names =T,row.names = F,sep = "\t",quote=F)
  #find the significant differential expressed genes for each clusters against all other clustershttp://127.0.0.1:14418/help/library/Venice/html/CreateSignacObject.html
  #feature plot of potential marker gene for each cluster
  #for each gene to be a potential marker,in add to be a significant expressed gene, the gene should account for
  #large proportion in the interested cluster but as small as possiable in the other clusters, that means the pct.1 should
  # be bigger than the pct.2.
  if ( as.logical(opt$strict) == T ){
    if ( !is.null(opt$pvalue) ){
      topn_markers  = global_DEGs %>%
        dplyr::group_by(cluster) %>%
        dplyr::filter(avg_log2FC>=opt$avg_log2FC & p_val < opt$pvalue & pct.1 > pct1_cutoff & pct.2 < pct2_cutoff & gene_diff > pct_fold_cutoff)  %>%
        dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
        dplyr::filter(gene_diff > pct_fold_cutoff)  %>%
        dplyr::top_n(topn,gene_diff)
    }else{
      topn_markers  = global_DEGs %>%
        dplyr::group_by(cluster) %>%
        dplyr::filter(avg_log2FC>=opt$avg_log2FC & p_val_adj < opt$FDR & pct.1 > pct1_cutoff & pct.2 < pct2_cutoff & gene_diff > pct_fold_cutoff)  %>%
        dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
        dplyr::filter(gene_diff > pct_fold_cutoff)  %>%
        dplyr::top_n(topn,gene_diff)
    }
  }else{
    topn_markers  = global_DEGs %>% dplyr::group_by(cluster) %>%
      #filter(p_val < opt$pvalue ) %>%
      dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
      # filter(gene_diff > pct_fold_cutoff)  %>%
      dplyr::top_n(topn,gene_diff)
  }
  write.table(topn_markers,file = file.path(output_dir,paste0("top", topn, "_markers_for_each_cluster.xls", collapse = "")),
              col.names =T,row.names = F,sep = "\t",quote=F)
  quit()
}

# ===================== Subcmd: subset the data object using condditional expression on cells =======
if ( "subset" %in% args ){ # subset the object using different conditions
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)
    group2use = opt$group2use
    levels = opt$levels
    data_obx = data_ob
    if ( is.null(opt$low) | opt$low == "NULL" ){
        opt$low = -Inf
    }
    if ( is.null(opt$high) | opt$high == "NULL" ){
        opt$high = Inf
    }
    if ( !is.null(levels)){
        levels_id = unlist(strsplit( levels,",",perl = T))
        if ( is.null(group2use) ){ group2use = "idents" }
        if ( group2use == "idents" ){
            if ( typeof(Idents(data_obx)) == "integer" ){ # the idents is clustering id
                data_obx = SubsetData(data_obx, ident.use = levels_id,
                                low.threshold = opt$low, high.threshold = opt$high)
            }
        } else{ #subset cells on metadata using other cell annotations
            data_obx = SubsetData(data_obx, subset.name = group2use,
                                   accept.value = levels_id,
                                   low.threshold = opt$low, high.threshold = opt$high
                      )
        }
        desired_cells = FetchData(data_obx, vars = rownames(data_obx)) %>% as.data.frame
    }else{
        desired_cells = FetchData(data_obx, vars = rownames(data_obx)) %>% as.data.frame
    }
    # subset cells on the expression matrix using logical exprssion on features
    if ( !is.null(opt$predicate) ){
        # levels = gsub( ".*\\((.*)\\)", "\\1", opt$cellfilter, perl =T)
        # predicate = gsub( "\\(.*\\)", glue::glue("({levels})"), opt$cellfilter, perl = T)

        df = OESingleCell::colData(data_obx)
        desired_cells= subset(df, eval( parse(text=opt$predicate)))
        data_obx = data_obx[, rownames(desired_cells) ]
    }

    if ( !is.null(opt$feature4subset) ){
        feature_predicate = opt$feature4subset
        count_df_T = Matrix::t(GetAssayData(data_obx, assay = opt$assay, slot = opt$slot))
        desired_cells = subset( as.data.frame(count_df_T), eval(expr = parse(text=feature_predicate)))
        data_obx = data_obx[, rownames(desired_cells)]
    }

    desired_cell_id = colnames(data_obx)

    # keep only specified features
    if ( !is.null( opt$geneset) ){
        genes = read.table(opt$geneset, sep = "\t", header = T)
        desired_features = as.vector( genes$gene)
    }else{
        desired_features = NULL
    }

    to_invert = opt$invert
    data_ob = subset(data_ob, features = desired_features,
                        cells = desired_cell_id, invert = to_invert)
    saveObject(data_ob, outdir = output_dir, splitby = opt$seperateby,
                outformat = opt$outformat, prefix = opt$prefix)
    quit()
}

# subcommand merge is invoked
if ( "merge" %in% args ){
  seuy = lapply(strsplit(opt$toadd, ","), function(seu){
      seux = readObject( input = seu, assay = opt$assay, informat = opt$adformat)
      if ( seux@version < 3 ){
          seux = UpdateSeuratObject(seux)
      }
  })
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  data_ob = merge( data_ob, y = seuy, merge.data = T)
  saveObject(data_ob, outdir = output_dir, splitby = opt$seperateby,
          outformat = opt$outformat, prefix = opt$prefix)
  quit()
}


# =============== Subcmd: updata the metedata of cells or features in the data_ob ============
if ( "update" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  if ( !is.null(opt$admeta) ){
      cellnames = Cells(data_ob)
      additional_metadata = read.csv(opt$admeta,sep=",",header =T )
      if ( opt$annlevel == "sample" ){
          #the index order is the same as the row index of the assay metadata
          sampleidx =  gsub("(_|-)[ATGC]{16,}.*","",cellnames,perl=T)
          #integrate the additional metadata from the assay design
          additional_cell_meta = vector()
          for ( colidx in colnames(additional_metadata) ){
              additional_cell_meta = cbind(additional_cell_meta,
              as.vector(additional_metadata[sampleidx, colidx]))
          }
          colnames(additional_cell_meta) = colnames(additional_metadata)
          rownames(additional_cell_meta) = cellnames
          additional_cell_meta = as.data.frame(additional_cell_meta)
          data_ob = AddMetaData( data_ob, additional_cell_meta)
      }else{# the annotation level is cell, make sure the barcodes are in the same pattern as the ones in the object
          additional_cell_meta = as.data.frame(additional_metadata)
          # TO DO if the cells in the supplied annotation is different from the cells in seurat object
          data_ob = AddMetaData( data_ob, metadata = additional_metadata)
      }
  }

  cellmeta = OESingleCell::colData(data_ob)
  if ( !is.null(opt$recode) ){
    # the format should be as follows:
    # seurat_clusters
    # 0:Naive CD4 T
    # 1:Memory CD4 T
    # 2:CD14+ Mono
    # 3:B
    # 4:CD8 T

    recode_df = read.table(opt$recode, header = T, sep = "\t")
    recode_id = colnames(recode_df)[1]
    from_to = recode_df %>% tidyr::separate(1, c("from", "to"), sep = ":") %>% tibble::deframe()
    new_meta = dplyr::recode(as.vector(cellmeta[[recode_id]]), !!!from_to )
    data_ob = OESingleCell::AddMetaData(data_ob, metadata = new_meta, col.name = recode_id )
  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}

if ( "split" %in% args ){
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat ) # all assay must be loaded

    if ( !is.null( opt$splitby) ){
        seurat_list = OESingleCell::SplitObject( data_ob, split.by = opt$splitby )
        lapply( names(seurat_list), function(x){
           SeuratDisk::SaveH5Seurat(seurat_list[[x]], filename = file.path(output_dir, glue::glue("{x}.rds")),overwrite = T )
        })
    }
    quit()
}

if ( "findneighbors" %in% args ){
  if (! is.null(opt$features)){
    if (! file.exists(opt$features)){
      stop((paste('Supplied genes file', opt$features, 'does not exist')))
    }else{
      features <- readLines(opt$features)
    }
  }

  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)

  data_ob <- Seurat::FindNeighbors(data_ob,
               k.param = opt$k_param,
               nn.method = opt$nn_method,
               annoy.metric = opt$dist_metric,
               nn.eps = opt$nn_eps,
               verbose = FALSE,
               force.recalc = opt$force_recalc,
               features = features,
               reduction = opt$reduction,
               dims = dims,
               assay = opt$assay,
               graph.name = opt$graph_name )
  OESingleCell::SaveX(data_ob, outformat = opt$outformat,output = opt$input, update = T, graphs = data_ob@graphs)

  quit()
}

if ( "metacell" %in% args ){
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)
    if ( !is.null( opt$features) ){
        genes = read.table(opt$features, sep = "\t", header = T)
        desired_features = as.vector( genes$gene)
    }else{
        desired_features = NULL
    }
    if ( !is.null(opt$avgby) ){
        avgby = opt$avgby
    }else{
        avgby = "clusters"
    }
    # data_ob = SetIdent( data_ob, value = avgby)
    Seurat::Idents(data_ob) = avgby
    avg_mtx = Seurat::AverageExpression(data_ob, assays = opt$assay, features = desired_features, slot = opt$slot)
    write.table(avg_mtx, file.path(output_dir,paste0("average_expression_matrix_by_",avgby,".xls")),
                sep = "\t", col.names = T,row.names = T)
    # output metadata either
}

if ( "rmambients" %in% args ){
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)

    # remove the empty droplets using dropletuitls if necessary
    emptyRemoved = RemoveEmptyDrops(
                  fdrThreshold=as.numeric(opt$fdr),
                  emptyDropNIters= as.numeric(opt$iters),
                  raw_count = GetAssayData(data_ob, slot = "counts") )
    subset_se = data_ob[, colnames(emptyRemoved)]
    # TO DO
    # make a UMI rank plot
    OESingleCell::SaveX(data_ob, output = opt$input, assay = assays[1],
                        outformat = opt$outformat,
                        update = F)
    quit()
}

# =============== Subcmd: normalize, normalize the data ============
if ( "normalize" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots, # counts only
                    verbose =F )
  if ( !is.null(opt$vars2regress) ){
    vars2regress = unlist(strsplit(opt$vars2regress, ",", perl =T))
  }else{
    vars2regress = NULL
  }

  if ( tolower(opt$nmethod) == "sct" ){
    data_ob = Seurat::SCTransform(data_ob, method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    SeuratDisk::UpdateH5Seurat(file = opt$input, data_ob, assay = "SCT", verbose = F)
    # OESingleCell::SaveX(data_ob, output = opt$input, assay = "SCT",
    #                   outformat = opt$outformat, update = T)
  }else{
    data_ob <- Seurat::NormalizeData(data_ob, normalization.method = opt$nmethod,
                             scale.factor = opt$scale_factor, margin = opt$margin,
                             block.size = opt$block_size, verbose = FALSE)
    OESingleCell::SaveX(data_ob, output = opt$input, assay = assays[1],
                      outformat = opt$outformat, update = T)
  }
  quit()
}

# =============== Subcmd: convert, change the data object to target format ============
if ( "convert" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  data_obx = ConvertX(data_ob, from = "", to = "")
  OESingleCell::SaveX(data_obx, output = opt$input, assay = assays[1],
                      outformat = opt$outformat,
                      update = F)
}

# Retreives data (feature expression, PCA scores, metrics, etc.) for a set of cells in a Seurat object
# =============== Subcmd: fetch, extract desired cell annotation ============
if ( "fetch" %in% args ){ # subcommand fetch is invoked
    if ( !is.null(opt$vars) ){
        var_list = unlist( strsplit(opt$vars, ",", perl = T) )
    }else{
        var_list = c("group", "ident")
    }
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)

    desired_df = OESingleCell::FetchData(data_ob, slot = dataslots[1], vars = var_list )
    desired_df$cellbarcode = rownames(desired_df)
    if ( !is.null(opt$header) ){
        colnames(desired_df) = unlist( strsplit(opt$header, ",", perl = T) )
    }
    write.table(desired_df, file.path(output_dir,
                glue::glue("{opt$prefix}_cellinfo.xls")),
                row.names = F,col.names = T, sep = "\t")
    quit()
}


# =============== Subcmd: downsample, subset cells randomly while keep heterogencity ============
if ( "downsample" %in% args ){  #### TO DO
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)

  data_ob = DownSample(data_ob, N = opt$targetN, slot = dataslots[1], PCs = opt$usePCA, verbose = F)

  output = file.path(output_dir, glue::glue("downsampled.{outformat}"))
  OESingleCell::SaveX(data_ob, output = output, outformat = opt$outformat, update = F)

  quit()
}

# =============== Subcmd: diffexp, find the differential expressed genes ============
if ( "diffexp" %in% args ){
  #parse the design
  if ( is.null( opt$design ) ){
      warning("NO assay design is PROVIDED\n")
  }else{
      design = opt$design
  }

  if ( is.null(opt$pvalue) && is.null(opt$fdr) ){
      stop("None of P-value or FDR is AVAILABLE! Filtering can be performed using any one of (-p), (-f) at one time.", call.=FALSE)
  }else if ( !is.null(opt$fdr)){
      fdr = as.numeric(opt$fdr)
      pvalue = NULL
  }else{
      pvalue = as.numeric(opt$pvalue)
      fdr = NULL
  }

 # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")

  #check the metadata of the assay design,which describe the expriement groupping of each
  #sample in the assay
  if ( !is.null( opt$addition_metadata)  ){ #the additional metadata for each sample
      add_assay_metadata = read.table(opt$addition_metadata,sep=",",header =T )
      # cellnames = data_ob@cell.names
      cellnames = colnames(data_ob) #seurat v3 style
      sampleidx =  gsub("_.*","",cellnames,perl=T) #the index order is the same as the row index of the assay metadata
      #integrate the additional metadata from the assay design
      additional_cell_meta = vector( )
      for ( colidx in colnames(add_assay_metadata) ){
          additional_cell_meta = cbind(additional_cell_meta, as.vector(add_assay_metadata[sampleidx, colidx]))
      }
      colnames(additional_cell_meta) = colnames(assay_metadata)
      rownames(additional_cell_meta) = cellnames
      additional_cell_meta = as.data.frame(additional_cell_meta)
      data_ob = AddMetaData( data_ob, additional_cell_meta )

      # assay_metadata = data_ob@meta.data
      assay_metadata = OESingleCell::colData(data_ob)
  }else{
      assay_metadata = OESingleCell::colData(data_ob)
  }

  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      desired_cells= subset(assay_metadata, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }


  #parse the contrast for this assay
  #if the constrast is not specified by the user explicitly from the command line,
  #the final differential result will use last level of the last variable in the
  #design formula over the first level of this variable. The levels for each
  #factor is aphabetly ordered by default,which can be reordered by the user.
  #if available,the contrast string from the user must obey the right format:
  #the_interested_factor:the_interested_levels_in_this_factor:the_reference_level_in_this_factor
  if ( is.null(opt$contrast ) ){ #no contrast is provided
      factors_indesign = strsplit(opt$design,"[~+ ]+",perl = T)
      last_factor_indesign = factors_indesign[length(factors_indesign)]
      if ( is.null(assay_metadata[,last_factor_indesign]) ){
          stop("The factor in design formula does not exist in assay metadata.")
      }
      variable_levels = levels(assay_metadata[,last_factor_indesign])
      contrast = paste( last_factor_indesign,variable_levels[length(variable_levels)],variable_levels[1],sep = ":" )
  }else{
      contrast = opt$contrast
  }
  contrasts = unlist( strsplit(contrast,":",perl = T) )
  all_levels = as.vector(unique(assay_metadata[,contrasts[1]]))
  if ( contrasts[2] == "all" & contrasts[3] != "all" ){
      all_levels = all_levels[-which(all_levels==contrasts[3])] #delete the reference level
      all_comparisions = paste(contrasts[1],all_levels,contrasts[3],sep = ":")
  }else if( contrasts[2] == "all" & contrasts[3] == "all" ){

      # combine_of2 = combn(all_levels,2) #random combination of two group
      # all_comparisions = c( paste(contrasts[1],combine_of2[2,],combine_of2[1,],sep = ":"),
      #                       paste(contrasts[1],combine_of2[1,],combine_of2[2,],sep = ":"))
      all_comparisions = lapply(all_levels,
                      function(x) paste(contrasts[1],x,paste0(all_levels[-which(all_levels==x)],collapse = ","),sep = ":"))
      all_comparisions = unlist(all_comparisions)
  }else if ( contrasts[2] != "all" & contrasts[3] == "all" ){
      #delete the interested level in the  reference level
      ref_levels = paste0(all_levels[-which(all_levels==contrasts[2])],collapse = ",")
      all_comparisions = paste(contrasts[1],contrasts[2],ref_levels,sep = ":")
  }else{
      all_comparisions = contrast
  }

  # Differential expression analysidataslotss
  #parse the contrast string to a list for later use
  future.apply::future_lapply( all_comparisions, function( contrast){
      OESingleCell::RunDiffexp( object = data_ob,
              test = opt$test,fdr = fdr,
              fc.thres = opt$FC,
              pval.thres = pvalue,
              contrast = contrast,
              outputdir = output_dir)
  }, future.seed = 2020)

  quit()
}

# =============== Subcmd: write10x, save the count matrix in mtx/h5 format ============
if ( "write10x" %in% args ){
  # read the specified assay and data slot in data object into memory
  # only counts dataslot needed here
  is.overwrite = as.logical(opt$overwrite)
  is.h5 = as.logical(opt$h5)

  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")
  if ( is.h5 ){
  }else{
    Write10X(data_ob, assay = assays,
             split.by = opt$split.by,
             version = opt$version,
             path = output_dir,
             overwrite = is.overwrite)
  }
  quit()
}

# =============== Subcmd: findhvg, find the variable features ============
if ( "findhvg" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots,  # counts is enough
                  verbose = F)

  if ( opt$select_method %in% c("vst", "dispsersion", "mean.var.plot") ){
    data_ob = OESingleCell::FindVariableFeatures(
      data_ob,
      assay = assays[1],
      selection.method = opt$select_method,
      loess.span = opt$loess_span,
      nfeatures = opt$nfeature,
      verbose = F)
  }else if ( opt$select_method %in% c("markvariogram", "moransi") ) {
      data_list = OESingleCell::SplitObject(data_ob,split.by="sampleid")
      spatial_DEGs_list = future.apply::future_lapply(1:length(data_list), function(sidx) {
        datax = Seurat::FindSpatiallyVariableFeatures(data_list[[sidx]] ,
                                            assay = assays[1],
                                            slot = "scale.data",
                                            image = Seurat::Images(data_list[[sidx]])[sidx],
                                            selection.method = opt$select_method,
                                            r.metric = 5,
                                            nfeatures = opt$nfeature,
                                            verbose = TRUE)
        spatial_DEGs = Seurat::SpatiallyVariableFeatures(datax, selection.method = tolower(opt$select_method) )
      })
      names(spatial_DEGs_list) = names(data_list)
      global_DEGs = stack(spatial_DEGs_list) %>% rename( gene = values, slice = ind)
      write.table(global_DEGs,
                  file = file.path(output_dir,paste0("top", nfeatures, "_for_all_spots.xls", collapse = "")),
                  col.names =T,row.names = F,sep = "\t",quote = FALSE)
  }

  if ( tolower(opt$outformat) == "h5seurat" ){
    hfile =  SeuratDisk::h5Seurat$new(filename = opt$input, mode = 'r+')
    on.exit(expr = hfile$close_all())
    assay_group = hfile[[glue::glue("assays/{assays[1]}")]]
    # Write out variable features
    assay_group$link_delete("variable.features")
    SeuratDisk::WriteH5Group( OESingleCell::VariableFeatures(data_ob),
                              name = 'variable.features',
                              hgroup = assay_group,
                              verbose = F)
    # Write out meta.features
    # attrs = hdf5r::h5attr_names(assay_group[["meta.features"]])
    # if ( length(attrs) ){
    #   sapply(attrs, function(x) assay_group[["meta.features"]]$attr_delete(x) )
    # }
    # assay_group$link_delete("meta.features")
    # assayx = Seurat::GetAssay( data_ob, assay = assays[1] )
    # print("XXXX")
    # currently I can not fix the error yet:
    # Can't create dataset _index - already exists!
    # SeuratDisk::WriteH5Group( assayx[[]], name = 'meta.features',
    #                           hgroup = assay_group,
    #                           verbose = F )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$input, outformat = opt$outformat)
  }
  quit()
}

# =============== Subcmd: scale, scale data and regress out variance ============
if ( "scale" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays,
                  data.use = dataslots,  # counts is enough
                  verbose = F)
  data_ob = Seurat::ScaleData(data_ob,
                          assay = assays[1],
                          vars.to.regress = unlist(strsplit(opt$vars2regress, ",", perl = T)),
                          split.by = NULL,
                          model.use = opt$model,
                          use.umi = as.logical(opt$use_umi),
                          scale.max = 10,
                          block.size = opt$block_size,
                          min.cells.to.block = 3000,
                          verbose = TRUE )
  OESingleCell::SaveX(data_ob, output = otp$input, assay = assays[1],
                      outformat = opt$outformat, update = T)

  quit()
}


# =============== Subcmd: score, gene module score calculation =========
if ( "score" %in% args ){
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays,
                  data.use = dataslots,  # data slot is enough
                  verbose = F)

  # gmt = GSEABase::getGmt(con=opt$gset)
  gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gmt))
  # filter gene sets
  gset_list = gset_list[lengths(gset_list)> opt$min.size]
  data_ob = Seurat::AddModuleScore(data_ob, features = gset_list, name = "module")

  cellmeta = OESingleCell::colData(data_ob)
  cellmeta = cellmeta %>%
              dplyr::rename_at(dplyr::vars(dplyr::starts_with("module")), ~ names(gset_list))
  gset_score = cellmeta %>%
                tibble::rownames_to_column(var = "barcode") %>%
                dplyr::select( barcode, names(gset_list) )
  write.table(gset_score, file = file.path(output_dir, "gene_module_scores.xls"), sep = "\t", row.names = F)

  if ( !is.null(opt$plot) ){
    vismethods = unlist(strsplit(opt$plot,","))
    # violin plot or featureplot for each gene module in specified group
    ccolors = unlist(strsplit(opt$ccolors,","))
    if ( length(ccolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
        info = glue::glue("the customized continious colors are: \n {paste(names(continious_palette), lengths(continious_palette), sep =': ', collapse = '\n')}.")
        warning("NO specified color schema found!")
        warning(info)
        stop()
      continious_colors = OESingleCell::SelectColors(palette = ccolors, is.discrete = FALSE)
    }else{ # this means to use the customized color schema from command line specified by user
      continious_colors = ccolors
    }

    switch(vismethods,
          "featureplot" = {
            suppressMessages({
              ggmodules = Seurat::FeaturePlot(data_ob,reduction= opt$reduct,
                              features = names(gset_list), split.by = opt$splitby,
                              keep.scale = "all",
                              max.cutoff = 'q99',
                              order = T,
                              pt.size = opt$pointsize) &
                          ggplot2::scale_color_gradientn(colours = continious_colors) &
                          ggplot2::theme(legend.position = "none",
                             legend.margin = ggplot2::margin(0,0.5,0,0, unit = "cm"),
                             plot.margin = ggplot2::margin(0, 0, 0, 0.1, unit = "cm"),
                             plot.title = ggplot2::element_text(hjust = 0.5) ) })
          ggm = ggpubr::ggarrange(ggmodules,common.legend = T, legend = "right")
          OESingleCell::save_ggplots(
              file.path(output_dir, "gene_module_featureplot"),
              width =  4*ifelse(is.null(splitby),yes = 2, no =length(unique(cellmeta[[splitby]]))),
              height = 3*ifelse(is.null(splitby),
                                yes = ceiling(length(topn_markers2vis)/2),
                                no  = length(topn_markers2vis)),
              plot = ggm, dpi = 1000 ,limitsize = F,bg="white" )
           },
          "vlnplot" = {
            gs = lapply(topn_markers2vis, function(x)
                        Seurat::VlnPlot(data_ob, features = x,
                                      cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                                      pt.size = opt$pointsize, alpha = opt$alpha2use,
                                      group.by = groupby,
                                      split.by = splitby,
                                      split.plot = as.logical(opt$dodge) )+
                        labs(title = "",y = x, x=NULL) +
                        ggplot2::theme( legend.position="none",
                          legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                          plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                            # unit(c(-0.1,2,-0.1,0.1), "null"),
                          # panel.spacing.x = unit(0.1,"null"),
                          axis.text = ggplot2::element_text(margin = unit(0,"null")),
                          axis.title.x = ggplot2::element_text(size = 0),
                          axis.title.y = ggplot2::element_text(size = 12),
                          axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                          axis.text.y=ggplot2::element_text(size = 8)))
                # gga = gridExtra::grid.arrange(grobs = gs, ncol=1, padding = unit(0, "line") )
                ggb = do.call(ggpubr::ggarrange,
                              c(gs,list( ncol = 1, align = "v", common.legend = TRUE, legend = "right")))
                OESingleCell::save_ggplots(plot = ggb,
                                 file.path(output_dir,"gene_module_violin_plot"),
                                 width = length(unique(cellmeta[[groupby]])),
                                 height = length(topn_markers2vis)*2)

          }
          )
  }
}


# =============== Subcmd: summarize, summarizing and visualizing the clustering analysis results =========
if ( "summarize" %in% args ){
  library(gridExtra)
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, reduction = opt$reduct, data.use = dataslots,  # data slot is enough
                  verbose = F)
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }
  
  if (!is.null(opt$predicate)) {
    df = OESingleCell::colData(data_ob)
    desired_cells = subset(df, eval(parse(text = opt$predicate)))
    data_ob = data_ob[, rownames(desired_cells)]
  }

  groupfactors = unlist(strsplit(opt$groupby, ",", perl = T))
  color_schema = OESingleCell::SelectColors(palette = opt$palette)
  for (groupfactor in groupfactors ){
    output_dir = file.path(output_dir, paste0( "visualize_cluster_by_", groupfactor, collapse = ""))
    if ( !file.exists(output_dir) ){
      dir.create(output_dir, recursive = T)
    }
    color_counter = 0
    nlevel = length(unique(OESingleCell::colData(data_ob)[[groupfactor]]))
    if ( !is.null(opt$facetby) ){
      for ( facetbyx in unlist( strsplit( opt$facetby, "," ) )){
         if ( !is.null(facetbyx) ){
             nrow = ceiling(length(unique(OESingleCell::colData(data_ob)[[facetbyx]]))/2)
             ncol = 2
         }
         #nlevel = length(unique(OESingleCell::colData(data_ob)[[groupfactor]]))
         color_counter = nlevel
         #data_ob = Seurat::SetIdent( data_ob, value = groupfactor)
         groupvis_split = Seurat::DimPlot(object = data_ob,
                          dims = c(1,2),reduction = opt$reduct,
                          pt.size = as.numeric(pointsize), ncol = 2,
                          group.by = groupfactor, split.by = facetbyx)+
             ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5))
         groupvis_split = groupvis_split +
                          ggplot2::scale_colour_manual( values = color_schema[1:nlevel],
                                               labels = sort(unique( data_ob@meta.data[,groupfactor] )) )

         OESingleCell::save_ggplots(file.path(output_dir,paste0("splitby-",facetbyx,"_split_plot",collapse="")),
                                    limitsize = FALSE, plot = groupvis_split, width = 14, height = 5*nrow )


         nfacet = length(unique(OESingleCell::colData(data_ob)[[facetbyx]]))
         groupvis_all = Seurat::DimPlot(object = data_ob, dims = c(1,2),
                                        reduction = opt$reduct,
                                        pt.size = as.numeric(pointsize),
                                        group.by = facetbyx)+
                         ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
                         ggplot2::scale_colour_manual( values = color_schema[1:nfacet])
         OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",facetbyx, "_contrast_plot",collapse="")),
                                    limitsize = FALSE, plot = groupvis_all, width = 7, height = 7 )
         color_counter = color_counter + nfacet

#### density plot
         groupby_df = subset(data_ob@meta.data, select = facetbyx)
         colnames(groupby_df) = "facetbyx"
         plot_data = Seurat::Embeddings(data_ob, reduction = opt$reduct)
         plot_data = cbind(plot_data, groupby_df)
         xx=(max(plot_data[,1])-min(plot_data[,1]))/10
         yy=(max(plot_data[,2])-min(plot_data[,2]))/10
         xlim = c(floor(min(plot_data[,1])-xx), ceiling(max(plot_data[,1])+xx))
         ylim = c(floor(min(plot_data[,2])-yy), ceiling(max(plot_data[,2])+yy))
         # ptsize = abs(xlim[2]-xlim[1])/nrow(plot_data)*50
         ptsize = abs(xlim[2]-xlim[1])*abs(ylim[2]-ylim[1])*0.4/nrow(plot_data)

         density_split = lapply(unique(plot_data$facetbyx), function(x) ggplot() + 
                                                                        stat_density_2d(geom="raster",contour = F,
                                                                                        data = subset(plot_data,facetbyx == x), alpha=1, 
                                                                                        aes_string(x = colnames(plot_data)[1], y = colnames(plot_data)[2], fill="..density..")) + 
                                                                        scale_fill_viridis_c(option = "magma") + 
                                                                        geom_point(data = subset(plot_data,facetbyx == x), 
                                                                                   aes_string(x = colnames(plot_data)[1], y = colnames(plot_data)[2]),
                                                                                   size = ptsize,shape = 16 ,color="white",alpha=0.7) + 
                                                                        xlim(xlim) + ylim(ylim) + labs(title = x) +
                                                                        theme(legend.position="none", plot.title = element_text(hjust = 0.5),
                                                                              axis.ticks.x=element_blank(), axis.text.x=element_blank(),
                                                                              axis.ticks.y=element_blank(), axis.text.y=element_blank(),
                                                                              panel.background = element_rect(fill = 'black', colour = 'black'), 
                                                                              panel.grid.major = element_line(colour = "black"),
                                                                              panel.grid.minor = element_line(colour = "black")))

         density_split_grid = gridExtra::grid.arrange(grobs = density_split, ncol = ncol)
         OESingleCell::save_ggplots(file.path(output_dir,paste0("splitby-",facetbyx,"_density_plot",collapse="")),
                                    limitsize = FALSE, plot = density_split_grid, width= ifelse(length(density_split)==1, 7, 6*ncol ), height = nrow*6 )

     }
    }else{
      if ( as.numeric(opt$dims) == 2 ){
          groupvis = Seurat::DimPlot(object = data_ob, dims = c(1,2),reduction = opt$reduct,
          pt.size = as.numeric(pointsize), group.by = groupfactor)+
              ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
              ggplot2::scale_colour_manual( values = color_schema[nlevel:nlevel*2])
          OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",groupfactor, "_contrast_plot",collapse="")),
                                     plot = groupvis,
                                     limitsize = FALSE, width = 15, height = 10 )
      }else{
          suppressPackageStartupMessages(library("SeuratPlotly"))
          groupvis = SeuratPlotly::DimPlotly3d(data_ob, reduction= opt$reduct,
                              pt_size = as.numeric(pointsize),
                              grouping_var = groupfactor,
                              plot_grid = F)
          htmlwidgets::saveWidget(groupvis, file = file.path(output_dir,paste0("groupby-",groupfactor,"_contrast_3D_plot.html",collapse="")))
      }
    }
  }

    if ( as.logical(opt$dosummary) ){
        data_ob = Seurat::SetIdent( data_ob, value = opt$groupby )
        data_ob@meta.data[[opt$groupby]] <- factor( data_ob@meta.data[[opt$groupby]],levels=unique(sort(data_ob@meta.data[[ opt$groupby]] )))
        DATA <- suppressMessages(OESingleCell::colData(data_ob)[,c("sampleid", opt$groupby)] %>%
                dplyr::group_by( .dots= c("sampleid", opt$groupby)) %>%
                dplyr::summarize(cell_number = dplyr::n()) %>%
                dplyr::mutate(freq = (cell_number / sum(cell_number)) * 100))
        write.table(as.data.frame(DATA), file.path(output_dir,file="clust_cond_freq_info.xls"),
                sep="\t", col.names=T, row.names =F)
        # visulaize the summary statistics of cells clusters in each groupping factor
        if ( !is.null(opt$facetby) ){
            for (facetbyx in unlist( strsplit( opt$facetby, "," ) )){
                clust_sum_all = OESingleCell::PlotAbundances(data_ob,
                                                     prop.by = opt$groupby,
                                                     group.by = facetbyx,
                                                     method = "barplot",
                                                     cols= unname(OESingleCell::SelectColors(1:length(unique(Seurat::Idents(data_ob))), palette = opt$palette)))
                OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",facetbyx,"_summary_plot",collapse="")),
                    dpi=1000, plot = clust_sum_all,width = 7, height = 7 )
             }
        }
        data_ob = Seurat::SetIdent(data_ob, value = "sampleid")
        clust_sum_all2 = OESingleCell::PlotAbundances(data_ob, prop.by = "sampleid",
                                        group.by = opt$groupby,
                                        method = "barplot",
                                        cols= unname(OESingleCell::SelectColors(1:length(unique(Seurat::Idents(data_ob))), palette = opt$palette)))
        OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",opt$groupby, "_summary_plot",collapse="")),
                                   dpi=1000, plot = clust_sum_all2,width = 7, height = 7 )
    }
    quit()
}

# =============== Subcmd: dimreduce, run dimension reduction =========
if ( "dimreduce" %in% args ){
  if ( is.null(opt$reduct1 )){
    print("NO first level dimension reduction methods specified,the default PCA will be used!")
    reduct1 = "pca"
  }else{
    reduct1 = tolower(opt$reduct1)
  }

  if ( !is.null(opt$reduct2) ){
    reduct2 = tolower(unlist(strsplit(opt$reduct2,",",  perl = T)))
  }else{
    # if no secondary reduction method specified, use primary reduction instead
    reduct2 = reduct1
  }

  if ( !is.null(opt$batchid) ){
    batchid = opt$batchid
  }

  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, reduction = opt$reduct, data.use = dataslots,  # data,scale.data
                  verbose = F)

  # get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  # check out wether the specified primary reduction has beed calculated
  is.rerun_reduct1 = FALSE; is.rerun_reduct2 = FALSE
  switch(as.character(opt$rerun),
         "reduct1" = {
           is.rerun_reduct1 = TRUE
         },
         "reduct2" = {
           is.rerun_reduct2 = TRUE
         },
         "all" = {
           is.rerun_reduct1 = TRUE
           is.rerun_reduct2 = TRUE
         } )

  if ( !is.null(reduct1 )){ # primary reduction is specified
    # if no previous reduction found, catch the error and rerun the
    # reduction without stop with error
    if ( !reduct1 %in% OESingleCell::Reductions(data_ob) | is.rerun_reduct1 ){
      print( "NO specified primary reduction found in the object! Rerun begins!")
      message(paste0("Beginning ", reduct1, " Dimension Reduction"))
      dim_outdir = file.path(output_dir,paste0(reduct1, "_Dimension_Reduction"))
      if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
      }

      data_ob = OESingleCell::RunDimReduc(data_ob, reduct1 = reduct1 ,
                              reduct2 = reduct1,
                              feature.use = OESingleCell::VariableFeatures(data_ob),
                              perplexity = perplexity,
                              assay.use = OESingleCell::DefaultAssay(data_ob),
                              batch.use = batchid, npcs.use = opt$components )
      reduct1_coord = OESingleCell::FetchData(data_ob,
                                var = c("rawbc", paste0(Seurat::Key(data_ob)[reduct1], 1:2))) %>%
                      dplyr::rename( "Barcode" = "rawbc")
      write.table( reduct1_coord, file.path(dim_outdir, paste0(reduct1, "_Dimension_Reduction_coordination.csv")),
                   sep = ",", col.names = T, row.names = F, quote = F)
    }else{
      print("The specified reduction results have beed calculated!Skip it!")
    }
  }

  if ( opt$reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
      #check the components
      # find the optimal components for secondary reduction
      optimal_pc = tryCatch(
                expr = Seurat::Command(data_ob, command = glue::glue("FindNeighbors.{opt$assay}.{opt$reduct1}"), value = "dims"),
                error = function(...){ return(NULL) }
              )
      if ( is.null(optimal_pc) ){ #if previous optimal components not available
          print( "NO previous optimal components is AVAILABLE, the optimal components number be detected automatically.")
          elb = Seurat::ElbowPlot(data_ob, reduction = opt$reduct1)
          optimal_pc = OESingleCell::FindElbow(elb$data)
          # suppressWarnings({ Misc(data_ob, "optimal_pc") = optimal_pc})
      }
  }else{ # reduct1 is not primary reduction and previouly run without primary reduction
          # the exception is mnn, it's better to be specified from command line with relative low value
          optimal_pc = min(opt$components, ncol(OESingleCell::Embeddings(data_ob,reduction = opt$reduct1)))
  }

  # different reduction method from primary reduction specified or forced to rerun
  if ( !opt$reduct2 %in% OESingleCell::Reductions(data_ob) | (opt$reduct2 != reduct1 & is.rerun_reduct2) ){
      message(paste0("Beginning ", opt$reduct2, " Dimension Reduction"))
      output_dir = file.path(output_dir,paste0(opt$reduct2, "_Dimension_Reduction"))
      if ( !dir.exists(output_dir) ){
        dir.create(output_dir, recursive = T)
      }

      data_ob = OESingleCell::RunDimReduc(data_ob, reduct1 = reduct1 , reduct2 = opt$reduct2,
                              feature.use = VariableFeatures(data_ob),
                              assay.use = DefaultAssay(data_ob),
                              batch.use = batchid, npcs.use = optimal_pc)
      reduct1_coord = OESingleCell::FetchData(data_ob,
                                var = c("rawbc", paste0( Key(data_ob)[opt$reduct2], 1:2))) %>%
                      dplyr::rename( "Barcode" = "rawbc")
      write.table( reduct1_coord, file.path(dim_outdir, paste0(opt$reduct2, "_Dimension_Reduction_coordination.csv")),
                   sep = ",", col.names = T, row.names = F, quote = F)
  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                                 reduction = unique(c(opt$reduct1, opt$reduct2)))
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }
  quit()
}

# =============== Subcmd: clusterx, run data clustering =========
if ( "clusterx" %in% args ){
   # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)

  # get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  if ( !is.null(opt$graphid) ){
    stopifnot( opt$graphid %in% SeuratObject::Graphs(data_ob) )
  }

  #Clustering with the reduction results using different clustering methods
  clustering.alg = c("snn" = 1, "louvain" = 2, "slm" = 3, "leidn" = 4)
  message(glue::glue("Beginning to group the cells using algorithm {opt$algorithm}!" ) )
  data_ob = Seurat::FindClusters(object = data_ob, resolution = opt$resolution,
                                 graph.name = opt$graphid,
                                 algorithm = clustering.alg[opt$algorithm], verbose = F)
  message("Clustering Finished!")

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }
  quit()
}

# =============== Subcmd: findneighbor, SNN or wSNN calculation =========
if ( "findneighbor" %in% args ){
   # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays,
                                data.use = dataslots, # data slot is enough
                                verbose = F)

  reductions = unlist(strsplit(opt$reduction, ",", perl = T))
  dims = lapply(unlist(strsplit(opt$dims, ",", perl = T)), function(x){eval( parse(text = x))})
  if ( length(assays) > 1 ){ # multimodal assays
    data_ob = Seurat::FindMultiModalNeighbors(data_ob,
                                              k.nn = opt$k_param,
                                              reduction.list = as.list(reductions),
                                              dims.list = dims,
                                              verbose = F)
  }else{ # monomodal assays
    data_ob = Seurat::FindNeighbors( data_ob,
                                   k.nn = opt$k_param,
                                   reduction = reductions[1],
                                   dims = dims[1],
                                   force.recalc = T, verbose = F)

  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                                 reduction = reductions, verbose = F)
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}


# =============== Subcmd: infercnv, copy number variation inference =========
if ( "infercnv" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays, # only RNA assay is valid
                                data.use = "counts", # counts slot is enough
                                verbose = F)

  # prepare the gene annotation file.
  if ( !is.null( opt$gene_order) ){
    gene_order_f = opt$gene_order
  }else if ( !is.null( opt$gtf ) ){
    gtf = plyranges::read_gff(opt$gtf)
    gene.chr = gtf %>% plyranges::filter(type == "gene" & gene_name %in% rownames(seurat_ob)) %>%
      as.data.frame() %>%
      dplyr::select(gene_name, seqnames, start, end) %>%
      dplyr::distinct(gene_name, .keep_all=T) %>%
      dplyr::mutate( seqnames = paste0("chr", seqnames))
    tempdir = tempdir()
    gene_order_f = file.path( tempdir, "gene_order_file.xls" )
    write.table(gene.chr, gene_order_f, col.names =F, row.names =F, sep = "\t", quote =F )
  }else{
    stop("NO gene coordination annotation file is not available!")
  }

  # if ( !is.null(opt$chr2exclude) ){
  #     chr2exclude = unlist(strsplit(opt$chr2exclude, ",", perl =T))
  # }else{
  #     chr2exclude = "chrM"
  # }

  # split the whole seurat to equal parts with almost same normal cells and tumor cells for pallalization.
  # for the tumor cells, equally seperate them to even parts.
  # for the normal cells, we tend to substract all the normal cells out and downsample to the desired number
  # for high efficiency.
  # then combine the same normal cells with different tumor cells parts.

  # make the celltype annotation file for CNV run
  #a description of the cells, indicating the cell type classifications.
  # The annotations_file, containing the cell name and the cell type classification, tab-delimited without header.
  #             V1                   V2
  # 1 MGH54_P2_C12 Microglia/Macrophage
  # 2 MGH36_P6_F03 Microglia/Macrophage
  # 3 MGH53_P4_H08 Microglia/Macrophage
  # 4 MGH53_P2_E09 Microglia/Macrophage
  # 5 MGH36_P5_E12 Oligodendrocytes (non-malignant)
  # 6 MGH54_P2_H07 Oligodendrocytes (non-malignant)
  # ...
  # 179  93_P9_H03 malignant
  # 180 93_P10_D04 malignant
  # 181  93_P8_G09 malignant
  # 182 93_P10_B10 malignant
  # 183  93_P9_C07 malignant
  # 184  93_P8_A12 malignant
  cellanno = FetchData(seurat_ob, vars = opt$celltype ) %>% tibble::rownames_to_column(var = "cellbarcode")
  if ( !is.null( opt$refgroup ) ){
    refcells = unlist(strsplit(opt$refgroup, ",", perl = T))
    count_mat = GetAssayData(seurat_ob, "counts")
  }else if ( !is.null( opt$malignant ) ){
    malignant = unlist(strsplit(opt$malignant, ",", perl = T))
    refcells = setdiff( unique(seurat_ob@meta.data[, opt$celltype]), malignant)
    count_mat = GetAssayData(seurat_ob, "counts")
  }else{
    print("NO reference normal cells or malignant cells are specified!
           The internal customized normal reference data will be used!")
    refexp = readRDSMC(opt$refexp, cores = 10)
    refcell_anno = data.frame(cellbarcode = colnames(refexp), celltype = "normal")
    cellanno = rbind(cellanno, refcell_anno )
    com.genes = intersect( rownames(seurat_ob), rownames(refexp) )
    count_mat = cbind(GetAssayData(seurat_ob, "counts")[com.genes,], refexp[com.genes,])
  }
  cnv_celltyping = file.path(tempdir, "cnv_celltype_group.xls")
  write.table(cellanno, cnv_celltyping, sep = "\t", col.names = F,row.names = F, quote = F)

  # main workflow
  infercnv_obj = infercnv::CreateInfercnvObject(raw_counts_matrix= count_mat,
                                      annotations_file= cnv_celltyping,
                                      delim="\t",
                                      gene_order_file= gene_order_f,
                                      ref_group_names=refcells)
  infercnv_obj = infercnv::run(infercnv_obj,
                               cutoff= opt$cutoff,
                               analysis_mode= opt$mode, # detect the subclusters  of tumor
                               tumor_subcluster_pval=opt$pval,
                               hclust_method = opt$clusting2use,
                               out_dir= output_dir,
                               num_threads=opt$ncores,
                               cluster_by_groups=TRUE,
                               denoise=TRUE,
                               no_plot = T,
                               no_prelim_plot = F,
                               HMM=as.logical(opt$doHMM))

  # visualize the cnv value for each cell in heatmap for optimal cluster numbers
  pdf( file.path(output_dir, "raw_heatmap.pdf"), width = 18, height = 12 )
  ComplexHeatmap::Heatmap(
    t(as.matrix(infercnv_obj@expr.data)),
    cluster_rows = FALSE,
    cluster_columns = FALSE,
    show_row_names =F,
    show_column_names = F,
    name="CNV level",
    use_raster=TRUE,
    raster_quality=4 )
  dev.off()

  # automatics cnv level inference for each cell
  if ( as.logical(opt$do_cnvlevel) ){
    # TO DO
  }

  quit()
}


# =============== Subcmd: vdj, parsing the vdj output from cellranger =========
if ( "vdj" %in% args ){
  vdj_path = normalizePath(sub("\\/$","",opt$vdj,perl=T))
  if (all(file.exists(Sys.glob(file.path(vdj_path,assay_metadata$sampleid))) )){
    # # glob all the clonotype annotation file for all the samples
    clonotypes_tbs = file.path(vdj_path,assay_metadata$sampleid,"outs","clonotypes.csv")
    names(clonotypes_tbs) = assay_metadata$sampleid
    json4samples = file.path(vdj_path,assay_metadata$sampleid,"outs","all_contig_annotations.json")
    names(json4samples) = assay_metadata$sampleid
  }else{
    stop("NO Cellranger VDJ output directory available! Please make sure the samples' ID in the metadata are the same as
        the output directories' name of the Cellranger VDJ results.")
  }
  # join the clonotype.csv and filtered_contig_annotations.csv table using the clonotype id
  # concatenate the table to relabel the clonotype id
  merged_profile = future.apply::future_lapply( names(json4samples), function(idx){
    # parse the all_contig_annotations.json file
    clonotypes_df = data.table::fread( clonotypes_tbs[idx]) %>% as_tibble() # read in the clonotypes.csv
    productive_summ = jsonlite::fromJSON(json4samples[idx]) %>% # all contig annotation nested data.frame
      dplyr::filter( is_cell != "FALSE" & high_confidence != "FALSE" & !is.null(cdr3) & productive == TRUE) %>%
      dplyr::mutate(raw_clonotype_id = info$raw_clonotype_id) %>%
      dplyr::select(-c("info", "filtered", "primer_annotations", "frame", "clonotype",
                "quals", "is_cell", "productive", "high_confidence")) %>%
      dplyr::drop_na( raw_clonotype_id ) %>% dplyr::drop_na(cdr3)
    anno_list = future.apply::future_lapply( productive_summ$annotations, function(anno){
      anno = anno %>%
        dplyr::select(-c("annotation_length","annotation_match_end",
                  "annotation_match_start","cigar","mismatches", "score" )) %>%
        dplyr::mutate( region_type = feature$region_type,  # extract the immune allel gene segment annotation
                region = feature$gene_name, chain = feature$chain) %>%
        dplyr::filter( !region_type %in% c("5'UTR", "C-REGION")) %>%
        dplyr::select(-feature)

      if ( !"D-REGION" %in% unique(anno[["region_type"]]) ){
        D_region = c(
          contig_match_end = "NA",
          contig_match_start = "NA",
          region_type = "D-REGION",
          region = "NA",
          chain = unique(anno[["chain"]])[1]
        )
        anno = rbind( anno, D_region[colnames(anno)] )
      }
      anno_row = anno %>%
        mutate(region_type = gsub( "L?-REGION\\+?", "", region_type, perl = T)) %>%
        arrange( factor( region_type, levels = c("V", "D", "J"))) %>%
        unite( "range", c("contig_match_start", "contig_match_end"), sep = ":") %>%
        unite( "segments", c("region", "range"), sep = ":") %>%
        summarize( segments= paste(segments, collapse=","), chain = unique(chain)[1]  )
    })
    anno_df = do.call(rbind, anno_list )
    productive_summ = cbind( productive_summ, anno_df ) %>% select(-annotations)%>%
      dplyr::rename( "clonotype_id" = "raw_clonotype_id",
                     "contig_id" = "contig_name", "cdr3_aa" = "cdr3", "cdr3_nt" = "cdr3_seq"  ) %>%
      inner_join( clonotypes_df, by = "clonotype_id") %>%
      select( -c("aa_sequence", "proportion", "frequency") ) %>%
      mutate( sampleid = idx ) %>%
      mutate( barcode = paste(sampleid, gsub("-\\d+","",barcode), sep = "-"))
    productive_summ
  })

  # merge all the annotation from each to one data.frame
  merged_profile = as.data.frame(do.call(rbind, merged_profile))

  # unification of two immunological sequences' annotation into one line in the same cell if exits.
  integrated_profile =  merged_profile %>%
    mutate( umis = umi_count,
            reads = read_count,
            chainx = chain,
            read_count = paste0( chain, ":", read_count),
            umi_count = paste0( chain, ":", umi_count),
            cdr3s_region = paste0(chain, ":", cdr3_start,"-", cdr3_stop),
            CDS_region = paste0(chain, ":", start_codon_pos, "-", stop_codon_pos)) %>%
    select( barcode, sampleid,contig_id, chain,cdr3s_aa, cdr3s_nt, cdr3s_region, chainx,
            segments, CDS_region, read_count, reads, umi_count,umis ) %>%
    group_by( barcode ) %>%
    summarize( # merge the paired VDJ annotation for each chain into one line
      sampleid = unique(sampleid),
      cdr3s_aa = unique(cdr3s_aa),
      cdr3s_nt = unique(cdr3s_nt),
      cdr3s_region = paste(unique(cdr3s_region), collapse=";"),
      segments= paste(segments, collapse=";"),
      CDS_region = paste(unique(CDS_region), collapse=";"),
      vdj_read_count = paste(unique(read_count), collapse=";"),
      vdj_umi_count = paste(unique(umi_count), collapse=";"),
      umis4cell = sum(unique(umis)),
      reads4cell = sum(unique(reads)) ) %>% ungroup()

  #
  clonotype_count = integrated_profile %>% group_by(cdr3s_aa) %>% tally() %>% arrange(desc(n))
  clonotype_count$clonotype_id =  paste("clonotype",1:dim(clonotype_count)[1],sep="")
  integrated_profile = inner_join(integrated_profile, clonotype_count,by = "cdr3s_aa") %>%
    arrange( desc(n)) %>% mutate(is_paired = ifelse(grepl(";", cdr3s_aa), "TRUE", "FALSE" )) %>%
    distinct() %>% mutate( id4cell = 1)
  write.table( integrated_profile, file.path(output_dir, "merged_vdj_contig_annotation.csv"),
               sep=",", quote = F, col.names = T, row.names=F)


  additional_cell_meta = vector()
  sampleidx =  gsub("(_|-)[ATCG]{16,}.*", integrated_profile$barcode,perl=T) #the index order is the same as the row index of the assay metadata
  for ( colidx in colnames(assay_metadata) ){
    additional_cell_meta = cbind(additional_cell_meta,
                                 as.vector(assay_metadata[sampleidx, colidx]))
  }
  colnames(additional_cell_meta) = colnames(assay_metadata)
  rownames(additional_cell_meta) = integrated_profile$barcode
  additional_cell_meta = additional_cell_meta %>%
    as.data.frame() %>%
    tibble::rownames_to_column(var = "barcode")
  integrated_profile = inner_join(additional_cell_meta,
                                  integrated_profile,
                                  by = c("barcode" = "barcode", "sampleid" = "sampleid"), keep = F)

  if ( !is.null(opt$seurat) ){
    seurat_ob = AddMetaData(seurat_ob, metadata = integrated_profile)
    # saveRDSMC(seurat_ob, opt$seurat)
  }
  # count the umi, reads or cells for each group
  for ( methodx in unlist( strsplit(opt$quant.use,",") ) ){
    countby = switch(
      tolower(methodx),
      "umi" = "umis4cell",
      "reads" = "reads4cell",
      "cells" = "id4cell"
    )

    clonotype_table = integrated_profile %>%
      select_at( c("sampleid", "clonotype_id", countby)) %>%
      rename("counts" = {{countby}}) %>%
      group_by(sampleid,clonotype_id) %>%
      summarise(counts = sum(counts)) %>% ungroup() %>%
      tidyr::spread(sampleid, counts,fill = 0) %>%
      mutate(total = rowSums(.[,2:dim(.)[2]])) %>%
      arrange(desc(total)) %>% dplyr::select(-total)

    write.table(clonotype_table, file.path(output_dir, glue::glue("clonotype_count_by_{methodx}_for_each_sample.xls")),
                 sep="\t", quote = F, col.names = T, row.names=F)

    if ( opt$maketse ){
      # make the TreeSummarizedExperiment as a data container of the sample level
      # clonotype annotation for diversity ananlysis
      tse_counts  = clonotype_table %>%
        tibble::column_to_rownames(var = "clonotype_id") %>% as.matrix()
      clonotype_anno = integrated_profile %>%
        select( clonotype_id, cdr3s_aa) %>%
        unique() %>% as_tibble() %>%
        tibble::column_to_rownames(var = "clonotype_id")
      tse = TreeSummarizedExperiment::TreeSummarizedExperiment(
        assays = list( counts = tse_counts ),
        colData = assay_metadata[colnames(tse_counts),],
        rowData =  clonotype_anno[rownames(tse_counts),] )
      saveRDS(tse, file.path(output_dir, glue::glue("vdj.tse.by.{methodx}.rds")))
    }
  }

  # change the format clonotype table to the specified
  future.apply::future_lapply(names(json4samples), function(idx){
    if ( opt$vdjformat == "vdjtools" ){
      parsed_vdj = merged_profile %>%
        dplyr::filter( sampleid == idx ) %>%
        dplyr::mutate( frequency = umi_count/sum(umi_count)) %>%
        dplyr::separate(segments,
                 c("V", "V.start", "V.end", "D", "D.start", "D.end", "J", "J.start", "J.end"), sep= ":|,") %>%
        dplyr::select( umi_count,frequency,cdr3_nt,cdr3_aa,V,D,J, V.end, D.start, D.end, J.start, barcode,cdr3s_aa, cdr3s_nt) %>%
        dplyr::rename( count = umi_count, CDR3nt = cdr3_nt, CDR3aa = cdr3_aa,
                Vend = V.end, Dstart = D.start, Dend = D.end, Jstart = J.start,
                clonotype_nt = cdr3s_nt, clonotype_aa = cdr3s_aa ) %>%
        dplyr::arrange(dplyr::desc(count))
      parsed_vdj[is.na( parsed_vdj) ]= "."
    }else if ( opt$vdjformat == "immunarch" ){
      parsed_vdj = merged_profile %>%
        dplyr::filter( sampleid == idx ) %>%
        dplyr::mutate( frequency = umi_count/sum(umi_count)) %>%
        dplyr::separate(segments,
                 c("V", "V.start", "V.end", "D", "D.start", "D.end", "J", "J.start", "J.end"), sep= ":|,") %>%
        dplyr::select( umi_count,frequency,cdr3_nt,cdr3_aa,V,D,J, V.end, D.start, D.end, J.start, contig_id, barcode, cdr3s_nt,cdr3s_aa) %>%
        dplyr::rename( count = umi_count, CDR3nt = cdr3_nt, CDR3aa = cdr3_aa, Vend = V.end, Dstart = D.start, Dend = D.end, Jstart = J.start,clonotype_nt = cdr3s_nt, clonotype_aa = cdr3s_aa  ) %>%
        dplyr::arrange(desc(count))
      parsed_vdj[is.na( parsed_vdj) ]= "."
    }
    write.table( parsed_vdj, file.path(output_dir, paste0( idx, ".xls", collapse = "")),
                 sep="\t", col.names = T, row.names=F, quote = F)
  })

  file_name = paste( rownames(assay_metadata), ".xls", sep = "")
  new_names = c("#file_name", colnames(assay_metadata) )
  assay_metadata = cbind( file_name, assay_metadata )
  colnames(assay_metadata) = new_names
  assay_metadata = assay_metadata %>% rename( sample.id = sampleid)
  write.table( assay_metadata, file.path(output_dir, "vdj_metadata.xls"),
               sep="\t", col.names = T, row.names=F, quote = F)
}



# =============== Subcmd: rmdoublets, remove the doublets from the data matrix =========
if ( "rmdoublets" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = OESingleCell::ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays, # only RNA assay is valid
                                data.use = "counts", # counts slot is enough
                                verbose = F)

}
# =============== Subcmd: annotation, add annotation to a genelist file =========
if ( "annotation" %in% args ){
  if (is.null(opt$anno)) {
    stop("Please provide the species information with parameter \"-a\" !")
  }else{
    marker = read.delim(opt$genelist, sep = "\t", stringsAsFactors = F)
    anno = read.delim(opt$anno,stringsAsFactors = F, sep = '\t')
    if (colnames(marker[1]) == "gene") {
      res = dplyr::left_join(marker, anno, by = c("gene" = "id"))
    }
    else {
      res = dplyr::left_join(marker, anno, by = c("GeneID" = "id"))
    }
    res[is.na(res)] = "--"
    write.table(res, paste0(strsplit(opt$genelist, "\\.xls")[[1]][1], "_anno.xls", collapse = ""), sep = '\t', quote = F, row.names = F)
  }
}
#######

if ( "changecelltype" %in% args){
    data_ob = OESingleCell::ReadX(input = opt$input, informat = opt$informat,
        assays = assays, data.use = dataslots)
    if ( as.logical(opt$barcode) ) {
          tsv <- read.delim(opt$celltype,sep=",",header=T)
          id = colnames(tsv)[2]
          # print("导入文件的new_celltype")
          print(table(tsv[,id]))
          if (dim(data_ob)[2]!=dim(tsv)[1] ) {
               print(paste0("注意：导入文件的barcodes数量为",dim(tsv)[1],"，rds中barcodes数量为",dim(data_ob)[2],"，注意对比信息"))
               if (length(setdiff(tsv[,colnames(tsv)[1]],data_ob@meta.data$rawbc)) != 0 ) {
                    stop(paste0("注意：",length(setdiff(tsv[,colnames(tsv)[1]],data_ob@meta.data$rawbc)),"条barcodes与rds中不匹配！！！！！！！！"))
               }
          }
          ### 给所有细胞进行细胞类型修改
          for (i in unique(tsv[,id]) ){
              subset_ob= subset(tsv, tsv[,id] == i)
              data_ob@meta.data[which(data_ob@meta.data$rawbc %in% as.vector(subset_ob[,colnames(tsv)[1]])) ,id] = i
          }
          # print("写入后rds的new_celltype")
          print(table(data_ob@meta.data[,id]))
    } else {
         tsv=read.table(opt$celltype,header=T,sep="\t",stringsAsFactors=F,colClasses="character")
         id=names(tsv)[1]
         tsv=tibble::column_to_rownames(tsv,id)
         a=list()
         b=c()
         for (i in rownames(tsv) ){
             a[[i]]=unlist(strsplit(tsv[i,],",",perl = T))
             for (cluster in a[[i]]){
               b=append(b,cluster)
               }
         }

         if ( "TRUE" %in% duplicated(b) ) {
               stop("There are duplicate clusters")
         } else if ( all(sort(b) %in% sort(levels(as.factor(data_ob@meta.data[,opt$cluster]))))) {
               to=c()
               for (name in names(a)){ for (cluster in a[[name]]) to[cluster]=name }
               data_ob@meta.data[,id] = plyr::mapvalues(x=data_ob@meta.data[,opt$cluster],
                 from=levels(as.factor(data_ob@meta.data[,opt$cluster])),
                 to=to[levels(as.factor(data_ob@meta.data[,opt$cluster]))])
               df = OESingleCell::colData(data_ob)
               desired_cells= subset(df, eval( parse(text = paste0(id," %in% c(names(a))"))))
               data_ob = data_ob[, rownames(desired_cells)]
               data_ob@meta.data[,id] = factor(data_ob@meta.data[,id] ,levels=names(a))  
         } else {
               stop("clusters are out of range")
         }
    }
          if ( id == "new_celltype" ) {
               data_ob@meta.data$new_celltype_col=""
               col_tmp = OESingleCell::SelectColors(1:length(unique(data_ob@meta.data$new_celltype)),palette=opt$palette)
               if ( class(data_ob@meta.data$new_celltype) == 'factor' ){
                 i = 1
                 for ( celltype in levels(data_ob@meta.data$new_celltype) ){
                     data_ob@meta.data[which(data_ob@meta.data$new_celltype == celltype),"new_celltype_col"] = as.character(col_tmp[i])
                     i = i + 1
                 }
               }else{
                 i = 1
                 for ( celltype in sort(unique(data_ob@meta.data$new_celltype)) ){
                     data_ob@meta.data[which(data_ob@meta.data$new_celltype == celltype),"new_celltype_col"] = as.character(col_tmp[i])
                     i = i + 1
                 }
               }
               print(table(data_ob@meta.data$new_celltype_col))
          } else {
               print("传入文件的表头不为new_celltype,不写入颜色信息")
          }
         if ( opt$reduct %in% names(data_ob@reductions) ){ ##判断二次降维方法是否输入错误
               reduct=opt$reduct
         } else {
               reduct=as.character(tail(names(data_ob@reductions),1))
               print(paste0(opt$reduct,"在RDS中不存在，使用",reduct,"作图"))
         }
         nlevel = length(unique(data_ob@meta.data[,id]))
         pointsize=0.5
         colors2use = OESingleCell::SelectColors(1:length(unique(OESingleCell::colData(data_ob)[[id]])),palette=opt$palette)
         gg = Seurat::DimPlot(object = data_ob, reduction = reduct,pt.size = pointsize,group.by=id)+
           ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
           ggplot2::scale_colour_manual( values = unname(colors2use))
         OESingleCell::save_ggplots(file.path(output_dir,id), gg, width = max(nchar(rownames(tsv)))/15+7, dpi = 1000,limitsize = F)
         
         simplified_meta = data_ob@meta.data %>%
                                   dplyr::rename( "Barcode" = "rawbc") %>%
                                    dplyr::select( Barcode, sampleid, opt$cluster, group,!!id)
         write.table(simplified_meta, quote = F,sep =",",row.names = F,
                  file.path(output_dir,paste0(id,".metadata.csv",collapse = "")))
       if ( as.logical(opt$update) ){
         SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
       }else{
         OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                             outformat = opt$outformat, prefix = opt$prefix)
       }
}
